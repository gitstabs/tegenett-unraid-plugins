<?xml version='1.0' standalone='yes'?>
<!DOCTYPE PLUGIN [
<!ENTITY name      "atp_emby_smart_cache">
<!ENTITY author    "Tegenett">
<!ENTITY version   "2026.01.29b">
<!ENTITY launch    "Settings/AtpEmbySmartCache">
<!ENTITY pluginURL "https://raw.githubusercontent.com/gitstabs/tegenett-unraid-plugins/main/atp_emby_smart_cache/atp_emby_smart_cache.plg">
]>

<PLUGIN name="&name;" author="&author;" version="&version;" launch="&launch;" pluginURL="&pluginURL;" icon="bolt" min="7.0.0" support="https://github.com/gitstabs/tegenett-unraid-plugins/issues">

<CHANGES>
##2026.01.29b
- UI: Responsive tables - all tables now support horizontal scrolling on mobile
- UI: ESC-style tabs - active tab fully highlighted for better visibility
- UI: Dashboard status colors - Running/Stopped clearly colored (green/red)
- UI: Mobile responsive improvements for tablets and phones

##2026.01.29a
- RENAME: Plugin renamed from emby_smart_cache to atp_emby_smart_cache (A Tegenett Plugin)
- SECURITY: All personal data removed from defaults (user must configure)
- SECURITY: CSRF token support added for Unraid 7
- UI: Colors updated to match ATP Backup theme (#e67e22)
- All paths updated to use atp_emby_smart_cache prefix
- NOTE: Requires fresh install - see migration guide

##2026.02.09.1 (previous version as emby_smart_cache)
- BUGFIX: Cooldown now properly waits before caching
- BUGFIX: Pre-cache next episodes now waits for cooldown first
- NEW: Configurable pre-cache episodes count (0-5)
- NEW: Rsync retry logic with exponential backoff
- NEW: Speed/time tracking for cache operations
</CHANGES>

<!-- Pre-install: Stop existing service and clean up -->
<FILE Run="/bin/bash">
<INLINE>
<![CDATA[
#!/bin/bash
PLUGIN_NAME="atp_emby_smart_cache"
PLUGIN_DIR="/usr/local/emhttp/plugins/${PLUGIN_NAME}"
LOG="/var/log/${PLUGIN_NAME}_install.log"

echo "$(date): Pre-install starting" >> "$LOG"

# Stop old service if running
if [ -f "/var/run/${PLUGIN_NAME}.pid" ]; then
    PID=$(cat /var/run/${PLUGIN_NAME}.pid)
    echo "$(date): Stopping service PID $PID" >> "$LOG"
    kill "$PID" 2>/dev/null
    sleep 3
fi
pkill -f "${PLUGIN_NAME}.py" 2>/dev/null || true

# Also stop old emby_smart_cache if migrating
pkill -f "emby_smart_cache.py" 2>/dev/null || true

rm -rf "${PLUGIN_DIR}"
mkdir -p "${PLUGIN_DIR}/include"

echo "$(date): Pre-install complete" >> "$LOG"
]]>
</INLINE>
</FILE>

<!-- Main Page File -->
<FILE Name="/usr/local/emhttp/plugins/&name;/AtpEmbySmartCache.page">
<INLINE>
<![CDATA[
Menu="Utilities"
Title="ATP Emby Smart Cache"
Icon="bolt"
---
<?php
// MUST be first - suppress ALL errors before anything else runs
error_reporting(0);
ini_set('display_errors', 0);

$plugin = "atp_emby_smart_cache";
$version = "v2026.01.29b";
$configFile = "/boot/config/plugins/{$plugin}/settings.json";
$dataDir = "/mnt/user/appdata/atp_emby_smart_cache";

// CSRF token for Unraid 7 security
$csrf_token = $var['csrf_token'] ?? '';

$defaults = [
    "ENABLED" => false,  // Disabled until configured
    "EMBY_HOST" => "",   // User must configure
    "EMBY_API_KEY" => "",
    "DISCORD_WEBHOOK_URL" => "",
    "SERVER_PORT" => 9999,
    "UNRAID_USER_PATH" => "/mnt/user",
    "CACHE_PATH" => "/mnt/cache",
    "ARRAY_ONLY_PATH" => "/mnt/user0",
    "LOG_FILE_PATH" => "/mnt/user/appdata/atp_emby_smart_cache/logs/atp_emby_smart_cache.log",
    "RSYNC_BWLIMIT" => "0",
    "MIN_FREE_SPACE_GB" => 100,
    "MAX_FILE_SIZE_GB" => 0,
    "SKIP_HARDLINKS" => true,
    "DELETE_ON_STOP" => true,
    "CLEANUP_DELAY_HOURS" => 24,
    "MOVER_IGNORE_FILE" => "",
    "ALLOWED_EXTS" => ".mkv,.mp4,.m4v,.avi,.mov,.ts",
    "EXCLUDE_PATHS" => "",
    "DOCKER_PATH_MAP" => "",
    "COOLDOWN_MOVIE_SEC" => 60,
    "COOLDOWN_EPISODE_SEC" => 30,
    "PRECACHE_EPISODES" => 1,
    "RSYNC_RETRIES" => 3,
    "LOG_RETENTION" => 5,
    "LOG_LEVEL" => "INFO"
];

$settings = $defaults;
if (file_exists($configFile)) {
    $loaded = json_decode(file_get_contents($configFile), true);
    if ($loaded) $settings = array_merge($defaults, $loaded);
}

// Get PID from PIDFILE (more reliable than pgrep which can match multiple processes)
$pidFile = "/var/run/{$plugin}.pid";
$pid = '';
$running = false;
if (file_exists($pidFile)) {
    $pid = trim(file_get_contents($pidFile));
    // Verify process is actually running
    if (!empty($pid) && file_exists("/proc/{$pid}")) {
        $running = true;
    } else {
        $pid = ''; // Stale PID file
    }
}

function apiCall($endpoint, $method = 'GET', $data = null) {
    global $settings;
    $port = isset($settings['SERVER_PORT']) ? intval($settings['SERVER_PORT']) : 9999;
    $url = "http://127.0.0.1:{$port}{$endpoint}";
    
    // Try curl first
    if (function_exists('curl_init')) {
        $ch = curl_init($url);
        curl_setopt($ch, CURLOPT_RETURNTRANSFER, true);
        curl_setopt($ch, CURLOPT_TIMEOUT, 5);
        curl_setopt($ch, CURLOPT_CONNECTTIMEOUT, 3);
        curl_setopt($ch, CURLOPT_FOLLOWLOCATION, false);
        if ($method === 'POST' && $data !== null) {
            curl_setopt($ch, CURLOPT_POST, true);
            curl_setopt($ch, CURLOPT_POSTFIELDS, json_encode($data));
            curl_setopt($ch, CURLOPT_HTTPHEADER, ['Content-Type: application/json']);
        }
        $resp = curl_exec($ch);
        $code = curl_getinfo($ch, CURLINFO_HTTP_CODE);
        $err = curl_error($ch);
        $errno = curl_errno($ch);
        curl_close($ch);
        
        if (!$err && $resp !== false && $code >= 200 && $code < 300) {
            $decoded = json_decode($resp, true);
            if ($decoded !== null) return $decoded;
        }
        // Log curl error for debugging
        $curlError = $err ?: "HTTP {$code}, errno {$errno}";
    } else {
        $curlError = "curl not available";
    }
    
    // Fallback to file_get_contents with stream context
    $context = stream_context_create([
        'http' => [
            'method' => $method,
            'header' => "Content-Type: application/json\r\n",
            'content' => ($method === 'POST' && $data) ? json_encode($data) : '',
            'timeout' => 5,
            'ignore_errors' => true
        ]
    ]);
    
    $resp = @file_get_contents($url, false, $context);
    if ($resp !== false) {
        $decoded = json_decode($resp, true);
        if ($decoded !== null) return $decoded;
    }
    
    return ['success' => false, 'error' => "API unavailable ({$curlError})", 'url' => $url];
}

if ($_SERVER['REQUEST_METHOD'] === 'POST' && isset($_POST['ajax'])) {
    header('Content-Type: application/json');
    $action = $_POST['ajax'];
    
    // Raw test to see what PHP actually outputs
    if ($action === 'raw_test') {
        die(json_encode(['success' => true, 'test' => 'OK', 'pid' => $pid, 'running' => $running]));
    }
    
    if ($action === 'get_status') {
        $result = apiCall('/api/status');
        // If API call failed but PID exists, show offline status
        if (!$result['success'] && $running) {
            $result = [
                'success' => true,
                'data' => [
                    'running' => false,
                    'uptime' => 0,
                    'active' => [],
                    'active_count' => 0,
                    'queue_count' => 0,
                    'managed_count' => 0,
                    'total_gb' => 0,
                    'api_error' => $result['error'] ?? 'API not responding'
                ]
            ];
        }
        echo json_encode($result);
    } elseif ($action === 'get_managed') {
        echo json_encode(apiCall('/api/managed'));
    } elseif ($action === 'get_queue') {
        echo json_encode(apiCall('/api/queue'));
    } elseif ($action === 'get_logs') {
        $lines = isset($_POST['lines']) ? intval($_POST['lines']) : 100;
        $result = apiCall("/api/logs?lines={$lines}");
        // Fallback: read log file directly if API fails
        if (!$result['success']) {
            $logPath = $settings['LOG_FILE_PATH'];
            if (is_dir($logPath)) $logPath = rtrim($logPath, '/') . "/atp_emby_smart_cache.log";
            if (file_exists($logPath)) {
                $logLines = file($logPath, FILE_IGNORE_NEW_LINES);
                $logLines = array_slice($logLines, -$lines);
                $result = ['success' => true, 'logs' => implode("\n", $logLines) . "\n[Read directly - API offline]"];
            }
        }
        echo json_encode($result);
    } elseif ($action === 'get_mover') {
        $result = apiCall('/api/mover_ignore');
        // Fallback: read mover ignore file directly if API fails
        if (!$result['success']) {
            $moverFile = $settings['MOVER_IGNORE_FILE'];
            if (!empty($moverFile) && file_exists($moverFile)) {
                $result = ['success' => true, 'content' => file_get_contents($moverFile) . "\n[Read directly - API offline]"];
            } else {
                $result = ['success' => true, 'content' => '(empty or not configured)'];
            }
        }
        echo json_encode($result);
    } elseif ($action === 'get_history') {
        echo json_encode(apiCall('/api/history'));
    } elseif ($action === 'force_cleanup') {
        $path = isset($_POST['path']) ? $_POST['path'] : '';
        echo json_encode(apiCall('/api/cleanup', 'POST', ['path' => $path]));
    } elseif ($action === 'rebuild_state') {
        echo json_encode(apiCall('/api/rebuild', 'POST', []));
    } elseif ($action === 'clear_log') {
        $logPath = $settings['LOG_FILE_PATH'];
        if (is_dir($logPath)) $logPath = rtrim($logPath, '/') . "/atp_emby_smart_cache.log";
        file_put_contents($logPath, "");
        echo json_encode(['success' => true, 'message' => 'Log cleared']);
    } elseif ($action === 'debug_api') {
        // Debug endpoint to test API connectivity
        $port = isset($settings['SERVER_PORT']) ? intval($settings['SERVER_PORT']) : 9999;
        $url = "http://127.0.0.1:{$port}/api/status";
        $debug = [
            'port' => $port,
            'url' => $url,
            'curl_available' => function_exists('curl_init'),
            'allow_url_fopen' => ini_get('allow_url_fopen')
        ];
        
        // Test curl
        if (function_exists('curl_init')) {
            $ch = curl_init($url);
            curl_setopt($ch, CURLOPT_RETURNTRANSFER, true);
            curl_setopt($ch, CURLOPT_TIMEOUT, 3);
            $resp = curl_exec($ch);
            $debug['curl_response'] = substr($resp ?: '', 0, 200);
            $debug['curl_error'] = curl_error($ch);
            $debug['curl_errno'] = curl_errno($ch);
            $debug['curl_http_code'] = curl_getinfo($ch, CURLINFO_HTTP_CODE);
            curl_close($ch);
        }
        
        // Test file_get_contents
        $ctx = stream_context_create(['http' => ['timeout' => 3]]);
        $resp2 = @file_get_contents($url, false, $ctx);
        $debug['fgc_response'] = substr($resp2 ?: '', 0, 200);
        $debug['fgc_error'] = $resp2 === false ? error_get_last()['message'] ?? 'unknown' : 'none';
        
        echo json_encode(['success' => true, 'debug' => $debug]);
    } elseif ($action === 'save_settings') {
        ob_start(); // Capture any stray output
        $new = $defaults;
        foreach ($defaults as $k => $v) {
            if (isset($_POST[$k])) {
                if (is_bool($v) || in_array($k, ['ENABLED','SKIP_HARDLINKS','DELETE_ON_STOP'])) {
                    $new[$k] = ($_POST[$k] === 'true' || $_POST[$k] === '1');
                } else {
                    $new[$k] = trim($_POST[$k]);
                }
            }
        }
        $saved = file_put_contents($configFile, json_encode($new, JSON_PRETTY_PRINT));
        $out = [];
        exec("/usr/local/emhttp/plugins/{$plugin}/rc.atp_emby_smart_cache restart 2>&1", $out, $ret);
        ob_end_clean(); // Discard any stray output
        $msg = $saved !== false ? 'Settings saved' : 'Failed to save settings';
        if (!empty($out)) $msg .= ', restart: ' . implode(' ', $out);
        echo json_encode(['success' => $saved !== false, 'message' => $msg]);
    }
    exit;
}

// Get PID from PIDFILE for page rendering
$pidFile = "/var/run/{$plugin}.pid";
$pid = '';
$running = false;
if (file_exists($pidFile)) {
    $pid = trim(file_get_contents($pidFile));
    if (!empty($pid) && file_exists("/proc/{$pid}")) {
        $running = true;
    } else {
        $pid = '';
    }
}
?>

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">

<style>
:root {
    --esc-primary: #e67e22;
    --esc-primary-dark: #d35400;
    --esc-success: #27ae60;
    --esc-warning: #f39c12;
    --esc-danger: #c0392b;
    --esc-info: #3498db;
    --esc-bg-dark: #1a1a1a;
    --esc-bg-card: #252525;
    --esc-border: #333;
    --esc-text: #e0e0e0;
    --esc-text-muted: #888;
}
.esc-container { max-width: 1400px; margin: 0 auto; }
.esc-header { display: flex; justify-content: space-between; align-items: center; padding: 15px 0; border-bottom: 2px solid var(--esc-primary); margin-bottom: 20px; }
.esc-header h1 { margin: 0; font-size: 24px; color: var(--esc-primary); }
.esc-header h1 i { margin-right: 10px; }
.esc-status-badge { padding: 6px 14px; border-radius: 20px; font-size: 13px; font-weight: bold; }
.esc-status-badge.running { background: var(--esc-success); color: #fff; }
.esc-status-badge.stopped { background: var(--esc-danger); color: #fff; }
.esc-tabs { display: flex; gap: 5px; margin-bottom: 20px; border-bottom: 1px solid var(--esc-border); padding-bottom: 10px; }
.esc-tab { padding: 10px 20px; background: var(--esc-bg-card); border: 1px solid var(--esc-border); border-radius: 5px 5px 0 0; cursor: pointer; color: var(--esc-text-muted); transition: all 0.2s; }
.esc-tab:hover { background: #333; color: var(--esc-text); }
.esc-tab.active { background: var(--esc-primary); color: #fff; border-color: var(--esc-primary); }
.esc-tab i { margin-right: 8px; }
.esc-panel { display: none; }
.esc-panel.active { display: block; }
.esc-grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 15px; margin-bottom: 20px; }
.esc-card { background: var(--esc-bg-card); border: 1px solid var(--esc-border); border-radius: 8px; padding: 20px; }
.esc-card-header { font-size: 12px; text-transform: uppercase; color: var(--esc-text-muted); margin-bottom: 8px; }
.esc-card-value { font-size: 28px; font-weight: bold; color: var(--esc-text); }
.esc-card-value.success { color: var(--esc-success); }
.esc-card-value.warning { color: var(--esc-warning); }
.esc-card-value.danger { color: var(--esc-danger); }
.esc-card-icon { float: right; font-size: 32px; opacity: 0.3; margin-top: -10px; }
.esc-table-wrapper { width: 100%; overflow-x: auto; -webkit-overflow-scrolling: touch; margin-bottom: 15px; }
.esc-table { width: 100%; border-collapse: collapse; background: var(--esc-bg-card); border-radius: 8px; overflow: hidden; min-width: 500px; }
.esc-table th, .esc-table td { padding: 12px 15px; text-align: left; border-bottom: 1px solid var(--esc-border); }
.esc-table th { background: #333; color: var(--esc-primary); font-weight: 600; text-transform: uppercase; font-size: 11px; white-space: nowrap; }
.esc-table tr:hover { background: #2a2a2a; }
.esc-table .filename { max-width: 400px; overflow: hidden; text-overflow: ellipsis; white-space: nowrap; }
.esc-table .truncate { max-width: 200px; overflow: hidden; text-overflow: ellipsis; white-space: nowrap; }

/* Dashboard status colors */
.success, .esc-text-success { color: var(--esc-success) !important; }
.danger, .esc-text-danger { color: var(--esc-danger) !important; }
.warning, .esc-text-warning { color: var(--esc-warning) !important; }
.info, .esc-text-info { color: var(--esc-info) !important; }
.esc-btn { padding: 8px 16px; border: none; border-radius: 4px; cursor: pointer; font-size: 13px; transition: all 0.2s; }
.esc-btn-primary { background: var(--esc-primary); color: #fff; }
.esc-btn-primary:hover { background: #e07b00; }
.esc-btn-danger { background: var(--esc-danger); color: #fff; }
.esc-btn-danger:hover { background: #d32f2f; }
.esc-btn-small { padding: 4px 10px; font-size: 11px; }
.esc-log-box { background: #111; color: #0f0; font-family: 'Courier New', monospace; font-size: 12px; padding: 15px; border-radius: 8px; height: 400px; overflow-y: auto; white-space: pre-wrap; word-wrap: break-word; user-select: text; -webkit-user-select: text; -moz-user-select: text; cursor: text; }
.esc-form-group { margin-bottom: 15px; }
.esc-form-group label { display: block; margin-bottom: 5px; color: var(--esc-text); font-weight: 500; }
.esc-form-group input, .esc-form-group select { padding: 8px 12px; border: 1px solid var(--esc-border); border-radius: 4px; background: #222; color: var(--esc-text); }
.esc-form-group input[type="text"], .esc-form-group input[type="number"] { width: 300px; }
.esc-form-group .help { font-size: 11px; color: var(--esc-text-muted); margin-top: 3px; }
.esc-section { background: var(--esc-bg-card); border: 1px solid var(--esc-border); border-radius: 8px; padding: 20px; margin-bottom: 20px; }
.esc-section-title { color: var(--esc-primary); font-size: 14px; font-weight: bold; text-transform: uppercase; margin-bottom: 15px; padding-bottom: 10px; border-bottom: 1px solid var(--esc-border); }
.esc-activity { max-height: 300px; overflow-y: auto; }
.esc-activity-item { padding: 10px; border-bottom: 1px solid var(--esc-border); display: flex; align-items: center; gap: 10px; }
.esc-activity-item:last-child { border-bottom: none; }
.esc-activity-icon { width: 32px; height: 32px; border-radius: 50%; display: flex; align-items: center; justify-content: center; }
.esc-activity-icon.copy { background: var(--esc-info); }
.esc-activity-icon.cleanup { background: var(--esc-warning); }
.esc-activity-icon.error { background: var(--esc-danger); }
.esc-spinner { display: inline-block; width: 16px; height: 16px; border: 2px solid #333; border-top-color: var(--esc-primary); border-radius: 50%; animation: esc-spin 1s linear infinite; }
@keyframes esc-spin { to { transform: rotate(360deg); } }
.esc-countdown { font-family: monospace; color: var(--esc-warning); }
.esc-refresh-indicator { font-size: 11px; color: var(--esc-text-muted); }
.esc-toolbar { display: flex; gap: 10px; margin-bottom: 15px; align-items: center; }

/* Health indicators */
.esc-health-item { display: flex; flex-direction: column; gap: 5px; }
.esc-health-label { font-size: 12px; color: var(--esc-text-muted); text-transform: uppercase; }
.esc-health-value { font-size: 14px; color: var(--esc-text); font-weight: 500; }
.esc-progress-bar { height: 8px; background: #333; border-radius: 4px; overflow: hidden; flex-grow: 1; min-width: 100px; }
.esc-progress-fill { height: 100%; background: var(--esc-success); transition: width 0.3s, background 0.3s; }
.esc-progress-fill.warning { background: var(--esc-warning); }
.esc-progress-fill.danger { background: var(--esc-danger); }

/* Mobile responsive - only affects small screens */
@media (max-width: 768px) {
    .esc-tabs { flex-wrap: wrap; gap: 3px; }
    .esc-tab { padding: 8px 12px; font-size: 12px; flex: 1 1 auto; text-align: center; min-width: 80px; }
    .esc-tab i { margin-right: 5px; display: none; }
    .esc-grid { grid-template-columns: repeat(2, 1fr); gap: 10px; }
    .esc-card { padding: 15px; }
    .esc-card-value { font-size: 22px; }
    .esc-card-icon { font-size: 24px; }
    .esc-table { font-size: 12px; }
    .esc-table th, .esc-table td { padding: 8px 10px; }
    .esc-table .filename { max-width: 150px; }
    .esc-header { flex-direction: column; gap: 10px; text-align: center; }
    .esc-header h1 { font-size: 20px; }
    .esc-form-group input[type="text"], .esc-form-group input[type="number"] { width: 100%; max-width: 300px; }
    .esc-section { padding: 15px; }
    .esc-toolbar { flex-wrap: wrap; }
    div[style*="grid-template-columns: 1fr 1fr"] { grid-template-columns: 1fr !important; }
}
@media (max-width: 480px) {
    .esc-tabs { gap: 2px; }
    .esc-tab { padding: 6px 8px; font-size: 11px; min-width: 60px; }
    .esc-grid { grid-template-columns: 1fr 1fr; }
    .esc-card-value { font-size: 18px; }
    .esc-log-box { height: 250px; font-size: 10px; }
}
</style>

<div class="esc-container">
    <div class="esc-header">
        <h1><i class="fa fa-bolt"></i> ATP Emby Smart Cache</h1>
        <div>
            <span class="esc-status-badge <?php echo $running ? 'running' : 'stopped'; ?>" id="statusBadge">
                <i class="fa <?php echo $running ? 'fa-check-circle' : 'fa-times-circle'; ?>"></i>
                <span id="statusText"><?php echo $running ? "Running (PID {$pid})" : "Stopped"; ?></span>
            </span>
            <span style="margin-left:15px; color:#888;"><?php echo $version; ?></span>
        </div>
    </div>

    <div class="esc-tabs">
        <div class="esc-tab active" data-tab="dashboard"><i class="fa fa-tachometer-alt"></i>Dashboard</div>
        <div class="esc-tab" data-tab="stats"><i class="fa fa-chart-bar"></i>Statistics</div>
        <div class="esc-tab" data-tab="files"><i class="fa fa-folder-open"></i>Managed Files</div>
        <div class="esc-tab" data-tab="queue"><i class="fa fa-clock"></i>Cleanup Queue</div>
        <div class="esc-tab" data-tab="logs"><i class="fa fa-terminal"></i>Logs</div>
        <div class="esc-tab" data-tab="settings"><i class="fa fa-cog"></i>Settings</div>
    </div>

    <!-- DASHBOARD PANEL -->
    <div class="esc-panel active" id="panel-dashboard">
        <div class="esc-grid">
            <div class="esc-card">
                <i class="fa fa-power-off esc-card-icon"></i>
                <div class="esc-card-header">Service Status</div>
                <div class="esc-card-value" id="dash-service">-</div>
            </div>
            <div class="esc-card">
                <i class="fa fa-clock esc-card-icon"></i>
                <div class="esc-card-header">Uptime</div>
                <div class="esc-card-value" id="dash-uptime">-</div>
            </div>
            <div class="esc-card">
                <i class="fa fa-sync esc-card-icon"></i>
                <div class="esc-card-header">Active Transfers</div>
                <div class="esc-card-value" id="dash-active">0</div>
            </div>
            <div class="esc-card">
                <i class="fa fa-hourglass-half esc-card-icon"></i>
                <div class="esc-card-header">Pending Cleanup</div>
                <div class="esc-card-value" id="dash-queue">0</div>
            </div>
            <div class="esc-card">
                <i class="fa fa-file-video esc-card-icon"></i>
                <div class="esc-card-header">Managed Files</div>
                <div class="esc-card-value" id="dash-managed">0</div>
            </div>
            <div class="esc-card">
                <i class="fa fa-database esc-card-icon"></i>
                <div class="esc-card-header">Total Cached</div>
                <div class="esc-card-value" id="dash-total">0 GB</div>
            </div>
        </div>

        <!-- System Health Section -->
        <div class="esc-section" style="margin-top:20px;">
            <div class="esc-section-title"><i class="fa fa-heartbeat"></i> System Health</div>
            <div style="display:grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap:15px;">
                <div class="esc-health-item">
                    <span class="esc-health-label">Cache Disk</span>
                    <div class="esc-progress-bar">
                        <div class="esc-progress-fill" id="health-cache-bar" style="width:0%"></div>
                    </div>
                    <span class="esc-health-value" id="health-cache-text">-</span>
                </div>
                <div class="esc-health-item">
                    <span class="esc-health-label">Array Disk</span>
                    <div class="esc-progress-bar">
                        <div class="esc-progress-fill" id="health-array-bar" style="width:0%"></div>
                    </div>
                    <span class="esc-health-value" id="health-array-text">-</span>
                </div>
                <div class="esc-health-item">
                    <span class="esc-health-label">Database Size</span>
                    <span class="esc-health-value" id="health-db-size">-</span>
                </div>
                <div class="esc-health-item">
                    <span class="esc-health-label">Log File Size</span>
                    <span class="esc-health-value" id="health-log-size">-</span>
                </div>
            </div>
        </div>

        <div style="display:grid; grid-template-columns: 1fr 1fr; gap:20px; margin-top:20px;">
            <div class="esc-section">
                <div class="esc-section-title"><i class="fa fa-bolt"></i> Active Transfers</div>
                <div id="active-transfers">
                    <p style="color:#888;">No active transfers</p>
                </div>
            </div>
            <div class="esc-section">
                <div class="esc-section-title"><i class="fa fa-history"></i> Recent Activity</div>
                <div class="esc-activity" id="recent-activity">
                    <p style="color:#888;">Loading...</p>
                </div>
            </div>
        </div>

        <div class="esc-toolbar" style="margin-top:20px;">
            <button class="esc-btn esc-btn-primary" onclick="rebuildState()"><i class="fa fa-sync"></i> Rebuild State</button>
            <button class="esc-btn" onclick="debugApi()" style="margin-left:10px;"><i class="fa fa-bug"></i> Debug API</button>
            <span class="esc-refresh-indicator">Auto-refresh: <span id="refresh-countdown">3</span>s</span>
        </div>
    </div>

    <!-- STATISTICS PANEL -->
    <div class="esc-panel" id="panel-stats">
        <div class="esc-grid">
            <div class="esc-card">
                <i class="fa fa-exchange-alt esc-card-icon"></i>
                <div class="esc-card-header">Total Moves</div>
                <div class="esc-card-value" id="stats-total-moves">0</div>
            </div>
            <div class="esc-card">
                <i class="fa fa-hdd esc-card-icon"></i>
                <div class="esc-card-header">Total GB Moved</div>
                <div class="esc-card-value" id="stats-total-gb">0 GB</div>
            </div>
            <div class="esc-card">
                <i class="fa fa-calendar esc-card-icon"></i>
                <div class="esc-card-header">Last Move</div>
                <div class="esc-card-value" id="stats-last-move">-</div>
            </div>
            <div class="esc-card">
                <i class="fa fa-chart-line esc-card-icon"></i>
                <div class="esc-card-header">Avg File Size</div>
                <div class="esc-card-value" id="stats-avg-size">-</div>
            </div>
        </div>

        <div style="display:grid; grid-template-columns: 1fr 1fr; gap:20px; margin-top:20px;">
            <div class="esc-section">
                <div class="esc-section-title"><i class="fa fa-chart-bar"></i> Activity Last 7 Days</div>
                <div style="height:200px; position:relative;">
                    <canvas id="chart-activity"></canvas>
                </div>
            </div>
            <div class="esc-section">
                <div class="esc-section-title"><i class="fa fa-database"></i> Storage Used Last 7 Days</div>
                <div style="height:200px; position:relative;">
                    <canvas id="chart-storage"></canvas>
                </div>
            </div>
        </div>

        <div class="esc-section" style="margin-top:20px;">
            <div class="esc-section-title"><i class="fa fa-list"></i> Top 10 Most Cached Files</div>
            <div class="esc-table-wrapper">
            <table class="esc-table" id="stats-top-files">
                <thead>
                    <tr>
                        <th>Filename</th>
                        <th>Times Cached</th>
                        <th>Total Size</th>
                    </tr>
                </thead>
                <tbody>
                    <tr><td colspan="3" style="text-align:center;color:#888;">Loading statistics...</td></tr>
                </tbody>
            </table>
            </div>
        </div>

        <div class="esc-toolbar" style="margin-top:20px;">
            <button class="esc-btn esc-btn-danger" onclick="resetStatistics()"><i class="fa fa-trash"></i> Reset Statistics</button>
            <span style="color:#888;font-size:12px;margin-left:10px;">Clear all activity history and reset counters</span>
        </div>
    </div>

    <!-- MANAGED FILES PANEL -->
    <div class="esc-panel" id="panel-files">
        <div class="esc-section">
            <div class="esc-section-title"><i class="fa fa-folder-open"></i> Files Currently on Cache</div>
            <div class="esc-table-wrapper">
            <table class="esc-table" id="managed-table">
                <thead>
                    <tr>
                        <th>Filename</th>
                        <th>Size</th>
                        <th>Cached At</th>
                        <th>Status</th>
                        <th>Action</th>
                    </tr>
                </thead>
                <tbody id="managed-tbody">
                    <tr><td colspan="5" style="text-align:center;color:#888;">Loading...</td></tr>
                </tbody>
            </table>
            </div>
        </div>

        <div class="esc-section">
            <div class="esc-section-title"><i class="fa fa-ban"></i> Mover Ignore List</div>
            <pre id="mover-content" style="background:#111;color:#ccc;padding:15px;border-radius:8px;max-height:200px;overflow-y:auto;font-size:12px;">Loading...</pre>
        </div>
    </div>

    <!-- CLEANUP QUEUE PANEL -->
    <div class="esc-panel" id="panel-queue">
        <div class="esc-section">
            <div class="esc-section-title"><i class="fa fa-clock"></i> Scheduled Cleanup Queue</div>
            <div class="esc-table-wrapper">
            <table class="esc-table" id="queue-table">
                <thead>
                    <tr>
                        <th>Filename</th>
                        <th>Scheduled For</th>
                        <th>Time Remaining</th>
                        <th>Action</th>
                    </tr>
                </thead>
                <tbody id="queue-tbody">
                    <tr><td colspan="4" style="text-align:center;color:#888;">Loading...</td></tr>
                </tbody>
            </table>
            </div>
        </div>
    </div>

    <!-- LOGS PANEL -->
    <div class="esc-panel" id="panel-logs">
        <div class="esc-toolbar">
            <button class="esc-btn esc-btn-danger" onclick="clearLog()"><i class="fa fa-trash"></i> Clear Log</button>
            <button class="esc-btn esc-btn-primary" id="refresh-logs-btn" onclick="refreshLogs(true)"><i class="fa fa-sync" id="refresh-logs-icon"></i> <span id="refresh-logs-text">Refresh</span></button>
        </div>
        <div class="esc-log-box" id="log-content">Loading...</div>
    </div>

    <!-- SETTINGS PANEL -->
    <div class="esc-panel" id="panel-settings">
        <form id="settings-form">
            <div class="esc-section">
                <div class="esc-section-title"><i class="fa fa-server"></i> Main Settings</div>
                <div class="esc-form-group">
                    <label>Enable Service</label>
                    <select name="ENABLED">
                        <option value="true" <?php echo $settings['ENABLED'] ? 'selected' : ''; ?>>Yes</option>
                        <option value="false" <?php echo !$settings['ENABLED'] ? 'selected' : ''; ?>>No</option>
                    </select>
                </div>
                <div class="esc-form-group">
                    <label>Emby Server URL</label>
                    <input type="text" name="EMBY_HOST" value="<?php echo htmlspecialchars($settings['EMBY_HOST']); ?>">
                </div>
                <div class="esc-form-group">
                    <label>Emby API Key</label>
                    <input type="text" name="EMBY_API_KEY" value="<?php echo htmlspecialchars($settings['EMBY_API_KEY']); ?>">
                </div>
                <div class="esc-form-group">
                    <label>Discord Webhook URL</label>
                    <input type="text" name="DISCORD_WEBHOOK_URL" value="<?php echo htmlspecialchars($settings['DISCORD_WEBHOOK_URL']); ?>" style="width:500px;">
                </div>
                <div class="esc-form-group">
                    <label>Local Webhook Port</label>
                    <input type="number" name="SERVER_PORT" value="<?php echo $settings['SERVER_PORT']; ?>" style="width:100px;">
                </div>
            </div>

            <div class="esc-section">
                <div class="esc-section-title"><i class="fa fa-sliders-h"></i> Performance & Logic</div>
                <div style="display:grid;grid-template-columns:1fr 1fr;gap:20px;">
                    <div class="esc-form-group">
                        <label>Movie Cooldown (sec)</label>
                        <input type="number" name="COOLDOWN_MOVIE_SEC" value="<?php echo $settings['COOLDOWN_MOVIE_SEC']; ?>" style="width:100px;">
                        <div class="help">Wait time before caching a movie</div>
                    </div>
                    <div class="esc-form-group">
                        <label>Episode Cooldown (sec)</label>
                        <input type="number" name="COOLDOWN_EPISODE_SEC" value="<?php echo $settings['COOLDOWN_EPISODE_SEC']; ?>" style="width:100px;">
                        <div class="help">Wait time before caching an episode</div>
                    </div>
                    <div class="esc-form-group">
                        <label>Pre-cache Next Episodes</label>
                        <input type="number" name="PRECACHE_EPISODES" value="<?php echo $settings['PRECACHE_EPISODES'] ?? 1; ?>" style="width:100px;" min="0" max="5">
                        <div class="help">How many next episodes to pre-cache (0=disabled)</div>
                    </div>
                    <div class="esc-form-group">
                        <label>Rsync Retries</label>
                        <input type="number" name="RSYNC_RETRIES" value="<?php echo $settings['RSYNC_RETRIES'] ?? 3; ?>" style="width:100px;" min="1" max="10">
                        <div class="help">Retry count on copy failure</div>
                    </div>
                    <div class="esc-form-group">
                        <label>Rsync Speed Limit (KBps)</label>
                        <input type="number" name="RSYNC_BWLIMIT" value="<?php echo $settings['RSYNC_BWLIMIT']; ?>" style="width:120px;">
                    </div>
                    <div class="esc-form-group">
                        <label>Min Free Space (GB)</label>
                        <input type="number" name="MIN_FREE_SPACE_GB" value="<?php echo $settings['MIN_FREE_SPACE_GB']; ?>" style="width:100px;">
                    </div>
                    <div class="esc-form-group">
                        <label>Max File Size (GB, 0=unlimited)</label>
                        <input type="number" step="0.1" name="MAX_FILE_SIZE_GB" value="<?php echo $settings['MAX_FILE_SIZE_GB']; ?>" style="width:100px;">
                    </div>
                    <div class="esc-form-group">
                        <label>Cleanup Delay (Hours)</label>
                        <input type="number" step="0.5" name="CLEANUP_DELAY_HOURS" value="<?php echo $settings['CLEANUP_DELAY_HOURS']; ?>" style="width:100px;">
                    </div>
                    <div class="esc-form-group">
                        <label>Cleanup Strategy</label>
                        <select name="DELETE_ON_STOP">
                            <option value="true" <?php echo $settings['DELETE_ON_STOP'] ? 'selected' : ''; ?>>Delete & Restore Original</option>
                            <option value="false" <?php echo !$settings['DELETE_ON_STOP'] ? 'selected' : ''; ?>>Keep on Cache</option>
                        </select>
                    </div>
                    <div class="esc-form-group">
                        <label>Hardlink Safety</label>
                        <select name="SKIP_HARDLINKS">
                            <option value="true" <?php echo $settings['SKIP_HARDLINKS'] ? 'selected' : ''; ?>>Skip Hardlinked Files (Safe)</option>
                            <option value="false" <?php echo !$settings['SKIP_HARDLINKS'] ? 'selected' : ''; ?>>Cache Anyway (Fast)</option>
                        </select>
                    </div>
                </div>
            </div>

            <div class="esc-section">
                <div class="esc-section-title"><i class="fa fa-folder"></i> Paths & Mappings</div>
                <div class="esc-form-group">
                    <label>User Share Path</label>
                    <input type="text" name="UNRAID_USER_PATH" value="<?php echo htmlspecialchars($settings['UNRAID_USER_PATH']); ?>" style="width:400px;">
                </div>
                <div class="esc-form-group">
                    <label>Cache Pool Path</label>
                    <input type="text" name="CACHE_PATH" value="<?php echo htmlspecialchars($settings['CACHE_PATH']); ?>" style="width:400px;">
                </div>
                <div class="esc-form-group">
                    <label>Array Only Path</label>
                    <input type="text" name="ARRAY_ONLY_PATH" value="<?php echo htmlspecialchars($settings['ARRAY_ONLY_PATH']); ?>" style="width:400px;">
                </div>
                <div class="esc-form-group">
                    <label>Log File Path</label>
                    <input type="text" name="LOG_FILE_PATH" value="<?php echo htmlspecialchars($settings['LOG_FILE_PATH']); ?>" style="width:500px;">
                </div>
                <div class="esc-form-group">
                    <label>Mover Ignore File</label>
                    <input type="text" name="MOVER_IGNORE_FILE" value="<?php echo htmlspecialchars($settings['MOVER_IGNORE_FILE']); ?>" style="width:500px;">
                </div>
                <div class="esc-form-group">
                    <label>Docker Path Mappings</label>
                    <input type="text" name="DOCKER_PATH_MAP" value="<?php echo htmlspecialchars($settings['DOCKER_PATH_MAP']); ?>" style="width:500px;">
                    <div class="help">Format: docker_path:host_path (comma separated for multiple)</div>
                </div>
                <div class="esc-form-group">
                    <label>Allowed Extensions</label>
                    <input type="text" name="ALLOWED_EXTS" value="<?php echo htmlspecialchars($settings['ALLOWED_EXTS']); ?>" style="width:400px;">
                </div>
                <div class="esc-form-group">
                    <label>Exclude Paths (comma separated)</label>
                    <input type="text" name="EXCLUDE_PATHS" value="<?php echo htmlspecialchars($settings['EXCLUDE_PATHS']); ?>" style="width:500px;">
                </div>
                <div class="esc-form-group">
                    <label>Log Retention (files)</label>
                    <input type="number" name="LOG_RETENTION" value="<?php echo $settings['LOG_RETENTION']; ?>" style="width:80px;">
                </div>
                <div class="esc-form-group">
                    <label>Log Level</label>
                    <select name="LOG_LEVEL" style="width:120px;">
                        <option value="DEBUG" <?php echo $settings['LOG_LEVEL'] === 'DEBUG' ? 'selected' : ''; ?>>DEBUG</option>
                        <option value="INFO" <?php echo $settings['LOG_LEVEL'] === 'INFO' ? 'selected' : ''; ?>>INFO</option>
                        <option value="WARNING" <?php echo $settings['LOG_LEVEL'] === 'WARNING' ? 'selected' : ''; ?>>WARNING</option>
                        <option value="ERROR" <?php echo $settings['LOG_LEVEL'] === 'ERROR' ? 'selected' : ''; ?>>ERROR</option>
                    </select>
                    <span style="color:#888;font-size:12px;margin-left:10px;">DEBUG shows most detail</span>
                </div>
            </div>

            <div style="text-align:center;margin-top:20px;">
                <button type="submit" class="esc-btn esc-btn-primary" id="save-btn" style="padding:12px 30px;font-size:15px;">
                    <i class="fa fa-save" id="save-icon"></i> <span id="save-text">Save Settings &amp; Restart Service</span>
                </button>
            </div>
        </form>
    </div>
</div>

<script src="https://cdn.jsdelivr.net/npm/chart.js@4.4.1/dist/chart.umd.min.js"></script>
<script>
// AJAX endpoint - use separate PHP file to bypass Unraid page template
var escAjaxUrl = '/plugins/atp_emby_smart_cache/include/ajax.php';
var escRefreshTimer = null;
var escCountdown = 3;
var escCurrentTab = 'dashboard';

$(function() {
    $('.esc-tab').click(function() {
        var tab = $(this).data('tab');
        $('.esc-tab').removeClass('active');
        $(this).addClass('active');
        $('.esc-panel').removeClass('active');
        $('#panel-' + tab).addClass('active');
        escCurrentTab = tab;
        escRefreshData();
    });

    $('#settings-form').submit(function(e) {
        e.preventDefault();
        var $btn = $('#save-btn');
        var $icon = $('#save-icon');
        var $text = $('#save-text');
        
        // Disable and show saving state
        $btn.prop('disabled', true);
        $icon.removeClass('fa-save').addClass('fa-spinner fa-spin');
        $text.text('Saving...');
        
        var fd = $(this).serialize() + '&ajax=save_settings';
        $.post(escAjaxUrl, fd, function(r) {
            if (r && r.success) {
                $icon.removeClass('fa-spinner fa-spin').addClass('fa-check');
                $text.text('Saved!');
                if (typeof swal !== 'undefined') {
                    swal({title:'Saved!', text:r.message || 'Settings saved', type:'success'});
                } else {
                    alert('Settings saved successfully!');
                }
            } else {
                $icon.removeClass('fa-spinner fa-spin').addClass('fa-times');
                $text.text('Error!');
                if (typeof swal !== 'undefined') {
                    swal({title:'Error', text:(r && r.error) || 'Failed to save', type:'error'});
                } else {
                    alert('Error: ' + ((r && r.error) || 'Failed to save'));
                }
            }
            setTimeout(function() {
                $btn.prop('disabled', false);
                $icon.removeClass('fa-check fa-times').addClass('fa-save');
                $text.text('Save Settings & Restart Service');
            }, 2000);
        }, 'json').fail(function(xhr, status, error) {
            $icon.removeClass('fa-spinner fa-spin').addClass('fa-times');
            $text.text('Error!');
            if (typeof swal !== 'undefined') {
                swal({title:'Error', text:'Request failed: ' + error, type:'error'});
            } else {
                alert('Request failed: ' + error);
            }
            setTimeout(function() {
                $btn.prop('disabled', false);
                $icon.removeClass('fa-times').addClass('fa-save');
                $text.text('Save Settings & Restart Service');
            }, 2000);
        });
    });

    escStartRefresh();
});

function escStartRefresh() {
    escRefreshData();
    escRefreshTimer = setInterval(function() {
        escCountdown--;
        $('#refresh-countdown').text(escCountdown);
        if (escCountdown == 0) {
            escCountdown = 3;
            escRefreshData();
        }
    }, 1000);
}

function escRefreshData() {
    if (escCurrentTab === 'dashboard') {
        escRefreshDashboard();
        escRefreshHealth();
    } else if (escCurrentTab === 'stats') {
        escRefreshStats();
    } else if (escCurrentTab === 'files') {
        escRefreshManaged();
        escRefreshMover();
    } else if (escCurrentTab === 'queue') {
        escRefreshQueue();
    }
    // Note: Logs tab does NOT auto-refresh (allows text selection)
    // User must click Refresh button manually
}

function escRefreshDashboard() {
    $.post(escAjaxUrl, {ajax: 'get_status'}, function(d) {
        if (d && d.success) {
            var s = d.data || d;
            // Check for API error (service running but not responding)
            if (s.api_error) {
                $('#dash-service').html('<span class="warning">API Offline</span>');
                $('#dash-uptime').text('-');
                $('#active-transfers').html('<p style="color:#ff9800;">' + escEscape(s.api_error) + '</p>');
            } else {
                $('#dash-service').html(s.running ? '<span class="success">Running</span>' : '<span class="danger">Stopped</span>');
                $('#dash-uptime').text(escFormatUptime(s.uptime || 0));
                $('#dash-active').text(s.active_count || 0);
                $('#dash-queue').text(s.queue_count || 0);
                $('#dash-managed').text(s.managed_count || 0);
                $('#dash-total').text((s.total_gb || 0).toFixed(1) + ' GB');
                
                var at = s.active || [];
                if (at.length === 0) {
                    $('#active-transfers').html('<p style="color:#888;">No active transfers</p>');
                } else {
                    var h = '';
                    for (var i = 0; i < at.length; i++) {
                        h += '<div class="esc-activity-item"><div class="esc-activity-icon copy"><i class="fa fa-sync fa-spin"></i></div><div>' + escEscape(at[i]) + '</div></div>';
                    }
                    $('#active-transfers').html(h);
                }
            }
        } else {
            $('#dash-service').html('<span class="danger">Offline</span>');
            $('#dash-uptime').text('-');
            $('#active-transfers').html('<p style="color:#f44336;">Service not responding</p>');
        }
    }, 'json').fail(function() {
        $('#dash-service').html('<span class="danger">Error</span>');
        $('#dash-uptime').text('-');
        $('#active-transfers').html('<p style="color:#f44336;">Connection failed</p>');
    });
    
    $.post(escAjaxUrl, {ajax: 'get_history'}, function(d) {
        if (d && d.success && d.data && d.data.length) {
            var h = '';
            for (var i = 0; i < Math.min(d.data.length, 10); i++) {
                var e = d.data[i];
                var ic = e.action === 'copy' ? 'copy' : (e.action === 'cleanup' ? 'cleanup' : 'error');
                var fa = e.action === 'copy' ? 'fa-copy' : (e.action === 'cleanup' ? 'fa-trash' : 'fa-exclamation');
                h += '<div class="esc-activity-item">';
                h += '<div class="esc-activity-icon ' + ic + '"><i class="fa ' + fa + '"></i></div>';
                h += '<div><strong>' + escEscape(e.filename) + '</strong><br><small style="color:#888;">' + escEscape(e.timestamp) + '</small></div>';
                h += '</div>';
            }
            $('#recent-activity').html(h);
        } else {
            $('#recent-activity').html('<p style="color:#888;">No recent activity</p>');
        }
    }, 'json').fail(function() {
        $('#recent-activity').html('<p style="color:#888;">No recent activity</p>');
    });
}

function escRefreshHealth() {
    $.post(escAjaxUrl, {ajax: 'get_health'}, function(d) {
        if (d && d.success && d.data) {
            var h = d.data;
            // Cache disk
            var cachePct = h.cache_used_pct || 0;
            $('#health-cache-bar').css('width', cachePct + '%').removeClass('warning danger');
            if (cachePct > 90) $('#health-cache-bar').addClass('danger');
            else if (cachePct > 75) $('#health-cache-bar').addClass('warning');
            $('#health-cache-text').text((h.cache_used_gb || 0).toFixed(1) + ' / ' + (h.cache_total_gb || 0).toFixed(0) + ' GB (' + cachePct.toFixed(0) + '%)');
            
            // Array disk
            var arrayPct = h.array_used_pct || 0;
            $('#health-array-bar').css('width', arrayPct + '%').removeClass('warning danger');
            if (arrayPct > 90) $('#health-array-bar').addClass('danger');
            else if (arrayPct > 75) $('#health-array-bar').addClass('warning');
            $('#health-array-text').text((h.array_used_gb || 0).toFixed(1) + ' / ' + (h.array_total_gb || 0).toFixed(0) + ' GB (' + arrayPct.toFixed(0) + '%)');
            
            // DB and Log size
            $('#health-db-size').text(h.db_size || '-');
            $('#health-log-size').text(h.log_size || '-');
        }
    }, 'json');
}

var escChartActivity = null;
var escChartStorage = null;

function escRefreshStats() {
    $.post(escAjaxUrl, {ajax: 'get_stats'}, function(d) {
        if (d && d.success && d.data) {
            var s = d.data;
            $('#stats-total-moves').text(s.total_moves || 0);
            $('#stats-total-gb').text((s.total_gb || 0).toFixed(1) + ' GB');
            $('#stats-last-move').text(s.last_move || '-');
            $('#stats-avg-size').text((s.avg_size_gb || 0).toFixed(2) + ' GB');
            
            // Update charts
            if (s.daily_activity) {
                escUpdateActivityChart(s.daily_activity);
            }
            if (s.daily_storage) {
                escUpdateStorageChart(s.daily_storage);
            }
            
            // Top files table
            if (s.top_files && s.top_files.length > 0) {
                var h = '';
                for (var i = 0; i < s.top_files.length; i++) {
                    var f = s.top_files[i];
                    h += '<tr><td class="filename">' + escEscape(f.filename) + '</td>';
                    h += '<td>' + f.count + '</td>';
                    h += '<td>' + (f.total_gb || 0).toFixed(2) + ' GB</td></tr>';
                }
                $('#stats-top-files tbody').html(h);
            } else {
                $('#stats-top-files tbody').html('<tr><td colspan="3" style="text-align:center;color:#888;">No data yet</td></tr>');
            }
        }
    }, 'json');
}

function escUpdateActivityChart(data) {
    var ctx = document.getElementById('chart-activity');
    if (!ctx) return;
    
    var labels = data.map(function(d) { return d.date; });
    var copies = data.map(function(d) { return d.copies || 0; });
    var cleanups = data.map(function(d) { return d.cleanups || 0; });
    
    if (escChartActivity) {
        escChartActivity.data.labels = labels;
        escChartActivity.data.datasets[0].data = copies;
        escChartActivity.data.datasets[1].data = cleanups;
        escChartActivity.update();
    } else if (typeof Chart !== 'undefined') {
        escChartActivity = new Chart(ctx, {
            type: 'bar',
            data: {
                labels: labels,
                datasets: [
                    { label: 'Copies', data: copies, backgroundColor: '#4caf50' },
                    { label: 'Cleanups', data: cleanups, backgroundColor: '#ff9800' }
                ]
            },
            options: {
                responsive: true,
                maintainAspectRatio: false,
                scales: { y: { beginAtZero: true, ticks: { stepSize: 1 } } },
                plugins: { legend: { labels: { color: '#aaa' } } }
            }
        });
    }
}

function escUpdateStorageChart(data) {
    var ctx = document.getElementById('chart-storage');
    if (!ctx) return;
    
    var labels = data.map(function(d) { return d.date; });
    var values = data.map(function(d) { return d.gb || 0; });
    
    if (escChartStorage) {
        escChartStorage.data.labels = labels;
        escChartStorage.data.datasets[0].data = values;
        escChartStorage.update();
    } else if (typeof Chart !== 'undefined') {
        escChartStorage = new Chart(ctx, {
            type: 'line',
            data: {
                labels: labels,
                datasets: [{ label: 'GB Cached', data: values, borderColor: '#ff9800', backgroundColor: 'rgba(255,152,0,0.1)', fill: true }]
            },
            options: {
                responsive: true,
                maintainAspectRatio: false,
                scales: { y: { beginAtZero: true } },
                plugins: { legend: { labels: { color: '#aaa' } } }
            }
        });
    }
}

function escRefreshManaged() {
    $.post(escAjaxUrl, {ajax: 'get_managed'}, function(d) {
        if (d && d.success && d.data && d.data.length) {
            var h = '';
            for (var i = 0; i < d.data.length; i++) {
                var f = d.data[i];
                h += '<tr>';
                h += '<td class="filename" title="' + escEscape(f.path) + '">' + escEscape(f.filename) + '</td>';
                h += '<td>' + (f.size_gb || 0).toFixed(2) + ' GB</td>';
                h += '<td>' + escEscape(f.cached_at || '-') + '</td>';
                h += '<td>' + (f.cleanup_at ? '<span class="esc-countdown">Cleanup scheduled</span>' : '<span style="color:#4caf50;">Active</span>') + '</td>';
                h += '<td><button class="esc-btn esc-btn-danger esc-btn-small" onclick="forceCleanup(\'' + escEscape(f.path).replace(/'/g, "\\'") + '\')">Cleanup</button></td>';
                h += '</tr>';
            }
            $('#managed-tbody').html(h);
        } else {
            $('#managed-tbody').html('<tr><td colspan="5" style="text-align:center;color:#888;">No managed files</td></tr>');
        }
    }, 'json').fail(function() {
        $('#managed-tbody').html('<tr><td colspan="5" style="text-align:center;color:#888;">No managed files</td></tr>');
    });
}

function escRefreshMover() {
    $.post(escAjaxUrl, {ajax: 'get_mover'}, function(d) {
        if (d && d.success) {
            $('#mover-content').text(d.content || '(empty)');
        } else {
            $('#mover-content').text('(empty)');
        }
    }, 'json').fail(function() {
        $('#mover-content').text('(unable to load)');
    });
}

function escRefreshQueue() {
    $.post(escAjaxUrl, {ajax: 'get_queue'}, function(d) {
        if (d && d.success && d.data && d.data.length) {
            var h = '';
            var now = Date.now() / 1000;
            for (var i = 0; i < d.data.length; i++) {
                var q = d.data[i];
                var remaining = Math.max(0, (q.cleanup_time || 0) - now);
                h += '<tr>';
                h += '<td class="filename">' + escEscape(q.filename) + '</td>';
                h += '<td>' + new Date((q.cleanup_time || 0) * 1000).toLocaleString() + '</td>';
                h += '<td class="esc-countdown">' + escFormatCountdown(remaining) + '</td>';
                h += '<td><button class="esc-btn esc-btn-danger esc-btn-small" onclick="forceCleanup(\'' + escEscape(q.path).replace(/'/g, "\\'") + '\')">Clean Now</button></td>';
                h += '</tr>';
            }
            $('#queue-tbody').html(h);
        } else {
            $('#queue-tbody').html('<tr><td colspan="4" style="text-align:center;color:#888;">No files in cleanup queue</td></tr>');
        }
    }, 'json').fail(function() {
        $('#queue-tbody').html('<tr><td colspan="4" style="text-align:center;color:#888;">No files in cleanup queue</td></tr>');
    });
}

function refreshLogs(showFeedback) {
    var $btn = $('#refresh-logs-btn');
    var $icon = $('#refresh-logs-icon');
    var $text = $('#refresh-logs-text');
    
    // Only show visual feedback if manually clicked
    if (showFeedback) {
        $btn.prop('disabled', true);
        $icon.removeClass('fa-sync').addClass('fa-spinner fa-spin');
        $text.text('Loading...');
    }
    
    $.post(escAjaxUrl, {ajax: 'get_logs', lines: 100}, function(d) {
        if (d && d.success) {
            $('#log-content').text(d.logs || 'No logs yet');
            var box = document.getElementById('log-content');
            box.scrollTop = box.scrollHeight;
            if (showFeedback) {
                $icon.removeClass('fa-spinner fa-spin').addClass('fa-check');
                $text.text('Updated!');
            }
        } else {
            $('#log-content').text('Unable to load logs');
            if (showFeedback) {
                $icon.removeClass('fa-spinner fa-spin').addClass('fa-times');
                $text.text('Error');
            }
        }
    }, 'json').fail(function() {
        $('#log-content').text('Failed to load logs - service may be offline');
        if (showFeedback) {
            $icon.removeClass('fa-spinner fa-spin').addClass('fa-times');
            $text.text('Error');
        }
    }).always(function() {
        if (showFeedback) {
            setTimeout(function() {
                $btn.prop('disabled', false);
                $icon.removeClass('fa-check fa-times').addClass('fa-sync');
                $text.text('Refresh');
            }, 1500);
        }
    });
}

function clearLog() {
    swal({
        title: 'Clear Log?',
        text: 'This will delete all log entries.',
        type: 'warning',
        showCancelButton: true,
        confirmButtonColor: '#f44336'
    }, function(confirmed) {
        if (confirmed) {
            $.post(escAjaxUrl, {ajax: 'clear_log'}, function(d) {
                swal({title: 'Done', text: d.message, type: 'success'});
                refreshLogs();
            }, 'json');
        }
    });
}

function forceCleanup(path) {
    swal({
        title: 'Force Cleanup?',
        text: 'This will delete the cache copy and restore the original file. This may take a moment for large files.',
        type: 'warning',
        showCancelButton: true,
        confirmButtonColor: '#f44336'
    }, function(confirmed) {
        if (confirmed) {
            // Show loading indicator
            swal({title: 'Processing...', text: 'Please wait while cleanup is in progress...', type: 'info', showConfirmButton: false});
            
            $.ajax({
                url: escAjaxUrl,
                method: 'POST',
                data: {ajax: 'force_cleanup', path: path},
                dataType: 'json',
                timeout: 120000  // 2 minute timeout for large files
            }).done(function(d) {
                swal({title: d.success ? 'Done' : 'Error', text: d.message || d.error || 'Cleanup executed', type: d.success ? 'success' : 'error'});
                escRefreshData();
            }).fail(function(xhr, status, error) {
                var msg = 'Request failed: ' + (error || status);
                if (xhr.responseText) {
                    msg += '\n\nResponse: ' + xhr.responseText.substring(0, 200);
                }
                swal({title: 'Error', text: msg, type: 'error'});
            });
        }
    });
}

function debugApi() {
    $.post(escAjaxUrl, {ajax: 'debug'}, function(d) {
        if (d && d.debug) {
            var msg = 'AJAX Handler Working!\n\n';
            msg += 'PHP Version: ' + d.debug.php_version + '\n';
            msg += 'curl available: ' + d.debug.curl_available + '\n';
            msg += 'Server IP: ' + d.debug.server_ip + '\n';
            msg += 'Port: ' + d.debug.port + '\n';
            msg += 'API URL: ' + d.debug.api_url + '\n';
            msg += 'Config exists: ' + d.debug.config_exists + '\n\n';
            msg += '--- CURL Test ---\n';
            msg += 'HTTP code: ' + d.debug.curl_http_code + '\n';
            msg += 'Error: ' + (d.debug.curl_error || 'none') + '\n';
            msg += 'Response: ' + (d.debug.curl_response || '(empty)').substring(0, 100);
            if (typeof swal !== 'undefined') {
                swal({title: 'API Debug', text: msg, type: d.debug.curl_http_code == 200 ? 'success' : 'warning'});
            } else {
                alert(msg);
            }
        } else {
            alert('Debug returned: ' + JSON.stringify(d));
        }
    }, 'json').fail(function(xhr) {
        alert('AJAX handler failed!\n\nResponse:\n' + xhr.responseText.substring(0, 400));
    });
}

function rebuildState() {
    swal({
        title: 'Rebuild State?',
        text: 'This will scan for .moved_to_cache files and rebuild the database.',
        type: 'info',
        showCancelButton: true
    }, function(confirmed) {
        if (confirmed) {
            // Show loading indicator
            swal({title: 'Rebuilding...', text: 'Please wait while state is being rebuilt...', type: 'info', showConfirmButton: false});
            
            $.ajax({
                url: escAjaxUrl,
                method: 'POST',
                data: {ajax: 'rebuild_state'},
                dataType: 'json',
                timeout: 60000  // 1 minute timeout
            }).done(function(d) {
                swal({title: d.success ? 'Done' : 'Error', text: d.message || d.error || 'State rebuilt', type: d.success ? 'success' : 'error'});
                escRefreshData();
            }).fail(function(xhr, status, error) {
                var msg = 'Request failed: ' + (error || status);
                if (xhr.responseText) {
                    msg += '\n\nResponse: ' + xhr.responseText.substring(0, 200);
                }
                swal({title: 'Error', text: msg, type: 'error'});
            });
        }
    });
}

function resetStatistics() {
    swal({
        title: 'Reset Statistics?',
        text: 'This will clear ALL activity history and reset counters. This cannot be undone.',
        type: 'warning',
        showCancelButton: true
    }, function(confirmed) {
        if (confirmed) {
            $.ajax({
                url: escAjaxUrl,
                method: 'POST',
                data: {ajax: 'reset_stats'},
                dataType: 'json',
                timeout: 30000
            }).done(function(d) {
                swal({title: d.success ? 'Done' : 'Error', text: d.message || d.error || 'Statistics reset', type: d.success ? 'success' : 'error'});
                escRefreshStats();
            }).fail(function(xhr, status, error) {
                swal({title: 'Error', text: 'Request failed: ' + (error || status), type: 'error'});
            });
        }
    });
}

function escFormatUptime(sec) {
    if (sec === 0 || isNaN(sec)) return '-';
    sec = Math.floor(sec);
    if (sec < 60) return sec + 's';
    if (sec < 3600) return Math.floor(sec / 60) + 'm ' + (sec % 60) + 's';
    if (sec < 86400) return Math.floor(sec / 3600) + 'h ' + Math.floor((sec % 3600) / 60) + 'm';
    return Math.floor(sec / 86400) + 'd ' + Math.floor((sec % 86400) / 3600) + 'h';
}

function escFormatCountdown(sec) {
    if (sec <= 0) return 'Now';
    sec = Math.floor(sec);
    if (sec < 60) return sec + 's';
    if (sec < 3600) return Math.floor(sec / 60) + 'm ' + (sec % 60) + 's';
    return Math.floor(sec / 3600) + 'h ' + Math.floor((sec % 3600) / 60) + 'm';
}

function escEscape(str) {
    if (!str) return '';
    var div = document.createElement('div');
    div.appendChild(document.createTextNode(str));
    return div.innerHTML;
}
</script>

]]>
</INLINE>
</FILE>

<!-- Python Daemon -->
<FILE Name="/usr/local/emhttp/plugins/&name;/&name;.py" Mode="0755">
<INLINE>
<![CDATA[
"""
ATP Emby Smart Cache - Python Daemon v2026.01.29
SQLite-backed state management with preserved file operation logic
Author: Tegenett
"""

import os
import sys
import time
import shutil
import logging
import subprocess
import threading
import json
import sqlite3
import signal
import urllib.request
import urllib.error
import glob
from pathlib import Path
from urllib.parse import urljoin, parse_qs, urlparse
from http.server import BaseHTTPRequestHandler, HTTPServer, ThreadingHTTPServer
from contextlib import contextmanager
from datetime import datetime

# ============================================
# CONFIGURATION
# ============================================

class Config:
    PLUGIN_NAME = "atp_emby_smart_cache"
    CONFIG_DIR = "/boot/config/plugins/atp_emby_smart_cache"
    DATA_DIR = "/mnt/user/appdata/atp_emby_smart_cache"
    DB_FILE = "state.db"
    SETTINGS_FILE = "settings.json"
    HIDDEN_SUFFIX = ".moved_to_cache"
    PARTIAL_SUFFIX = ".partial"

    # DEFAULTS - All paths are generic, user MUST configure these
    DEFAULTS = {
        "ENABLED": False,  # Disabled until configured
        "EMBY_HOST": "",   # User must set: http://YOUR_EMBY_IP:8096
        "EMBY_API_KEY": "",  # User must set: Get from Emby Dashboard > API Keys
        "DISCORD_WEBHOOK_URL": "",
        "SERVER_PORT": 9999,
        "UNRAID_USER_PATH": "/mnt/user",
        "CACHE_PATH": "/mnt/cache",  # Generic default
        "ARRAY_ONLY_PATH": "/mnt/user0",
        "LOG_FILE_PATH": "/mnt/user/appdata/atp_emby_smart_cache/logs/atp_emby_smart_cache.log",
        "RSYNC_BWLIMIT": "0",  # 0 = unlimited
        "MIN_FREE_SPACE_GB": 100,
        "MAX_FILE_SIZE_GB": 0,
        "SKIP_HARDLINKS": True,
        "DELETE_ON_STOP": True,
        "CLEANUP_DELAY_HOURS": 24,
        "MOVER_IGNORE_FILE": "",
        "ALLOWED_EXTS": ".mkv,.mp4,.m4v,.avi,.mov,.ts",
        "EXCLUDE_PATHS": "",
        "DOCKER_PATH_MAP": "",  # User must set if using Docker paths
        "COOLDOWN_MOVIE_SEC": 60,
        "COOLDOWN_EPISODE_SEC": 30,
        "PRECACHE_EPISODES": 1,
        "RSYNC_RETRIES": 3,
        "LOG_RETENTION": 5,
        "LOG_LEVEL": "INFO"
    }
    
    C = DEFAULTS.copy()
    ALLOWED_EXTS_SET = set()
    ALLOWED_SUB_EXTS = {'.srt', '.sub', '.idx', '.vtt', '.ass', '.smi'}
    EXCLUDE_LIST = []
    PATH_MAP = {}
    
    # SAFETY: Valid mount point prefixes (prevents writing to RAM)
    VALID_MOUNT_PREFIXES = [
        "/mnt/user",
        "/mnt/cache",
        "/mnt/disk",
        "/mnt/user0",
        "/mnt/remotes",
    ]
    
    @classmethod
    def validate_path(cls, path_str):
        """
        CRITICAL SAFETY CHECK: Validate that a path is on a real disk mount.
        Returns True if valid, False if path could write to RAM.
        """
        path_str = str(path_str)
        if not path_str.startswith("/mnt/"):
            return False
        for prefix in cls.VALID_MOUNT_PREFIXES:
            if path_str.startswith(prefix):
                return True
        return False

    @classmethod
    def load(cls):
        os.makedirs(cls.CONFIG_DIR, exist_ok=True)
        os.makedirs(cls.DATA_DIR, exist_ok=True)
        os.makedirs(os.path.join(cls.DATA_DIR, "logs"), exist_ok=True)
        
        path = os.path.join(cls.CONFIG_DIR, cls.SETTINGS_FILE)
        if os.path.exists(path):
            try:
                with open(path, 'r') as f:
                    cls.C.update(json.load(f))
            except Exception as e:
                print(f"Config load error: {e}")
        
        # Type conversions
        try: cls.C["SERVER_PORT"] = int(cls.C["SERVER_PORT"])
        except: cls.C["SERVER_PORT"] = 9999
        try: cls.C["COOLDOWN_MOVIE_SEC"] = int(cls.C["COOLDOWN_MOVIE_SEC"])
        except: cls.C["COOLDOWN_MOVIE_SEC"] = 60
        try: cls.C["COOLDOWN_EPISODE_SEC"] = int(cls.C["COOLDOWN_EPISODE_SEC"])
        except: cls.C["COOLDOWN_EPISODE_SEC"] = 30
        try: cls.C["PRECACHE_EPISODES"] = int(cls.C["PRECACHE_EPISODES"])
        except: cls.C["PRECACHE_EPISODES"] = 1
        try: cls.C["RSYNC_RETRIES"] = int(cls.C["RSYNC_RETRIES"])
        except: cls.C["RSYNC_RETRIES"] = 3
        try: cls.C["MIN_FREE_SPACE_GB"] = int(cls.C["MIN_FREE_SPACE_GB"])
        except: cls.C["MIN_FREE_SPACE_GB"] = 300
        try: cls.C["MAX_FILE_SIZE_GB"] = float(cls.C["MAX_FILE_SIZE_GB"])
        except: cls.C["MAX_FILE_SIZE_GB"] = 0.0
        try: cls.C["CLEANUP_DELAY_HOURS"] = float(cls.C["CLEANUP_DELAY_HOURS"])
        except: cls.C["CLEANUP_DELAY_HOURS"] = 24.0
        
        bw = str(cls.C.get("RSYNC_BWLIMIT", "50000")).strip()
        cls.C["RSYNC_BWLIMIT"] = bw if bw.isdigit() else "50000"
        
        cls.ALLOWED_EXTS_SET = set(x.strip().lower() for x in cls.C.get("ALLOWED_EXTS", "").split(',') if x.strip())
        cls.EXCLUDE_LIST = [x.strip() for x in cls.C.get("EXCLUDE_PATHS", "").split(',') if x.strip()]
        
        cls.PATH_MAP = {}
        if cls.C.get("DOCKER_PATH_MAP"):
            for pair in cls.C["DOCKER_PATH_MAP"].split(','):
                if ':' in pair:
                    parts = pair.split(':', 1)
                    if len(parts) == 2:
                        cls.PATH_MAP[parts[0].strip()] = parts[1].strip()

Config.load()

# ============================================
# LOGGING
# ============================================

LOG_FILE = Config.C.get('LOG_FILE_PATH', '/var/log/atp_emby_smart_cache.log')
if os.path.isdir(LOG_FILE):
    LOG_FILE = os.path.join(LOG_FILE, "atp_emby_smart_cache.log")

os.makedirs(os.path.dirname(LOG_FILE), exist_ok=True)

# Get log level from config
_log_level_str = Config.C.get('LOG_LEVEL', 'INFO').upper()
_log_level = getattr(logging, _log_level_str, logging.INFO)

logging.basicConfig(
    filename=LOG_FILE,
    level=_log_level,
    format='%(asctime)s [%(levelname)s] %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
console = logging.StreamHandler()
console.setLevel(_log_level)
console.setFormatter(logging.Formatter('%(asctime)s [%(levelname)s] %(message)s'))
logging.getLogger('').addHandler(console)
logger = logging.getLogger(__name__)

START_TIME = time.time()

# ============================================
# DATABASE
# ============================================

class Database:
    def __init__(self):
        self.db_path = os.path.join(Config.DATA_DIR, Config.DB_FILE)
        # Use RLock to allow re-entrant locking (same thread can acquire multiple times)
        self.lock = threading.RLock()
        self._init_db()
    
    def _init_db(self):
        with self._conn() as conn:
            conn.executescript('''
                CREATE TABLE IF NOT EXISTS managed_files (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    user_path TEXT UNIQUE NOT NULL,
                    cache_path TEXT,
                    array_path TEXT,
                    filename TEXT,
                    size_bytes INTEGER DEFAULT 0,
                    cached_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    cleanup_at TIMESTAMP
                );
                
                CREATE TABLE IF NOT EXISTS cleanup_queue (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    user_path TEXT UNIQUE NOT NULL,
                    filename TEXT,
                    scheduled_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    cleanup_time TIMESTAMP NOT NULL
                );
                
                CREATE TABLE IF NOT EXISTS activity_log (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    action TEXT NOT NULL,
                    filename TEXT,
                    path TEXT,
                    details TEXT
                );
                
                CREATE TABLE IF NOT EXISTS stats (
                    key TEXT PRIMARY KEY,
                    value TEXT
                );
                
                CREATE INDEX IF NOT EXISTS idx_managed_user ON managed_files(user_path);
                CREATE INDEX IF NOT EXISTS idx_queue_user ON cleanup_queue(user_path);
                CREATE INDEX IF NOT EXISTS idx_activity_time ON activity_log(timestamp);
                CREATE INDEX IF NOT EXISTS idx_activity_action ON activity_log(action);
                CREATE INDEX IF NOT EXISTS idx_activity_action_time ON activity_log(action, timestamp);
            ''')
            
            # Initialize stats if not exist
            conn.execute("INSERT OR IGNORE INTO stats (key, value) VALUES ('total_moves', '0')")
            conn.execute("INSERT OR IGNORE INTO stats (key, value) VALUES ('total_gb_moved', '0.0')")
            conn.execute("INSERT OR IGNORE INTO stats (key, value) VALUES ('last_move_date', '')")
    
    @contextmanager
    def _conn(self):
        acquired = self.lock.acquire(timeout=30)
        if not acquired:
            logger.error("DB: Could not acquire lock within 30 seconds!")
            raise Exception("Database lock timeout")
        try:
            conn = sqlite3.connect(self.db_path, timeout=30, isolation_level='DEFERRED')
            conn.row_factory = sqlite3.Row
            # Enable WAL mode for better concurrency
            conn.execute("PRAGMA journal_mode=WAL")
            conn.execute("PRAGMA busy_timeout=30000")
            try:
                yield conn
                conn.commit()
            except Exception as e:
                logger.error(f"DB: Rolling back due to error: {e}")
                conn.rollback()
                raise
            finally:
                conn.close()
        except Exception as e:
            logger.error(f"Database connection error: {e}")
            raise
        finally:
            self.lock.release()
    
    def add_managed_file(self, user_path, cache_path, array_path, filename, size_bytes, log_action='copy'):
        with self._conn() as conn:
            conn.execute('''
                INSERT OR REPLACE INTO managed_files 
                (user_path, cache_path, array_path, filename, size_bytes, cached_at)
                VALUES (?, ?, ?, ?, ?, CURRENT_TIMESTAMP)
            ''', (str(user_path), str(cache_path), str(array_path), filename, size_bytes))
        # Log activity AFTER connection is closed (use specified action type)
        if log_action:
            self._log_activity(log_action, filename, str(user_path), f"Size: {size_bytes/(2**30):.2f} GB")
    
    def remove_managed_file(self, user_path):
        filename = None
        with self._conn() as conn:
            row = conn.execute("SELECT filename FROM managed_files WHERE user_path = ?", (str(user_path),)).fetchone()
            if row:
                filename = row['filename']
                conn.execute("DELETE FROM managed_files WHERE user_path = ?", (str(user_path),))
        # Log activity AFTER connection is closed to avoid nested locks
        if filename:
            self._log_activity('cleanup', filename, str(user_path), 'File removed from cache')
            return True
        return False
    
    def get_managed_files(self):
        with self._conn() as conn:
            return [dict(row) for row in conn.execute(
                "SELECT * FROM managed_files ORDER BY cached_at DESC"
            ).fetchall()]
    
    def is_managed(self, user_path):
        with self._conn() as conn:
            return conn.execute(
                "SELECT 1 FROM managed_files WHERE user_path = ?", (str(user_path),)
            ).fetchone() is not None
    
    def schedule_cleanup(self, user_path, filename, delay_hours):
        cleanup_time = time.time() + (delay_hours * 3600)
        with self._conn() as conn:
            conn.execute('''
                INSERT OR REPLACE INTO cleanup_queue (user_path, filename, cleanup_time)
                VALUES (?, ?, datetime(?, 'unixepoch'))
            ''', (str(user_path), filename, cleanup_time))
    
    def remove_from_queue(self, user_path):
        with self._conn() as conn:
            cursor = conn.execute("DELETE FROM cleanup_queue WHERE user_path = ?", (str(user_path),))
            return cursor.rowcount > 0
    
    def get_cleanup_queue(self):
        with self._conn() as conn:
            return [dict(row) for row in conn.execute('''
                SELECT *, strftime('%s', cleanup_time) as cleanup_time_unix
                FROM cleanup_queue ORDER BY cleanup_time ASC
            ''').fetchall()]
    
    def get_pending_cleanups(self):
        with self._conn() as conn:
            return [dict(row) for row in conn.execute('''
                SELECT * FROM cleanup_queue 
                WHERE cleanup_time <= datetime('now')
            ''').fetchall()]
    
    def update_stats(self, filename, size_gb):
        with self._conn() as conn:
            # Increment total moves
            conn.execute('''
                UPDATE stats SET value = CAST(CAST(value AS INTEGER) + 1 AS TEXT) 
                WHERE key = 'total_moves'
            ''')
            # Add to total GB
            current = float(conn.execute("SELECT value FROM stats WHERE key = 'total_gb_moved'").fetchone()[0])
            conn.execute("UPDATE stats SET value = ? WHERE key = 'total_gb_moved'", (str(current + size_gb),))
            # Update last move date
            conn.execute("UPDATE stats SET value = ? WHERE key = 'last_move_date'", 
                        (datetime.now().strftime('%Y-%m-%d %H:%M:%S'),))
    
    def get_stats(self):
        with self._conn() as conn:
            stats = {}
            for row in conn.execute("SELECT key, value FROM stats").fetchall():
                stats[row['key']] = row['value']
            managed_count = conn.execute("SELECT COUNT(*) FROM managed_files").fetchone()[0]
            queue_count = conn.execute("SELECT COUNT(*) FROM cleanup_queue").fetchone()[0]
            total_size = conn.execute("SELECT COALESCE(SUM(size_bytes), 0) FROM managed_files").fetchone()[0]
            stats['managed_count'] = managed_count
            stats['queue_count'] = queue_count
            stats['total_cached_bytes'] = total_size
            return stats
    
    def _log_activity(self, action, filename, path, details=''):
        try:
            with self._conn() as conn:
                conn.execute('''
                    INSERT INTO activity_log (action, filename, path, details)
                    VALUES (?, ?, ?, ?)
                ''', (action, filename, path, details))
                # Keep only last 1000 entries
                conn.execute('''
                    DELETE FROM activity_log WHERE id NOT IN (
                        SELECT id FROM activity_log ORDER BY timestamp DESC LIMIT 1000
                    )
                ''')
        except Exception as e:
            logger.error(f"Activity log error: {e}")
    
    def get_activity(self, limit=50):
        with self._conn() as conn:
            return [dict(row) for row in conn.execute('''
                SELECT * FROM activity_log ORDER BY timestamp DESC LIMIT ?
            ''', (limit,)).fetchall()]
    
    def get_statistics(self):
        """Get comprehensive statistics for the Statistics tab"""
        stats = {
            'total_moves': 0,
            'total_gb': 0,
            'last_move': '-',
            'avg_size_gb': 0,
            'daily_activity': [],
            'daily_storage': [],
            'top_files': []
        }
        
        try:
            with self._conn() as conn:
                # Total moves (copy actions only - not recovery)
                row = conn.execute("SELECT COUNT(*) as cnt FROM activity_log WHERE action = 'copy'").fetchone()
                stats['total_moves'] = row['cnt'] if row else 0
                
                # Last move timestamp
                row = conn.execute("SELECT timestamp FROM activity_log WHERE action = 'copy' ORDER BY timestamp DESC LIMIT 1").fetchone()
                if row:
                    stats['last_move'] = row['timestamp']
                
                # Total GB from current managed files (this is accurate)
                row = conn.execute("SELECT SUM(size_bytes) as total FROM managed_files").fetchone()
                if row and row['total']:
                    stats['total_gb'] = row['total'] / (2**30)
                
                # Average file size from current managed files
                row = conn.execute("SELECT AVG(size_bytes) as avg FROM managed_files").fetchone()
                if row and row['avg']:
                    stats['avg_size_gb'] = row['avg'] / (2**30)
                
                # Daily activity for last 7 days
                rows = conn.execute('''
                    SELECT DATE(timestamp) as date,
                           SUM(CASE WHEN action = 'copy' THEN 1 ELSE 0 END) as copies,
                           SUM(CASE WHEN action = 'cleanup' THEN 1 ELSE 0 END) as cleanups
                    FROM activity_log
                    WHERE timestamp >= DATE('now', '-7 days')
                    GROUP BY DATE(timestamp)
                    ORDER BY date
                ''').fetchall()
                stats['daily_activity'] = [{'date': r['date'], 'copies': r['copies'], 'cleanups': r['cleanups']} for r in rows]
                
                # Daily storage - parse size from details field ("Size: X.XX GB")
                rows = conn.execute('''
                    SELECT DATE(timestamp) as date, details
                    FROM activity_log
                    WHERE action = 'copy' AND timestamp >= DATE('now', '-7 days')
                ''').fetchall()
                
                daily_gb = {}
                for r in rows:
                    date = r['date']
                    details = r['details'] or ''
                    # Parse "Size: X.XX GB" from details
                    try:
                        if 'Size:' in details:
                            size_str = details.split('Size:')[1].strip().split()[0]
                            size_gb = float(size_str)
                            daily_gb[date] = daily_gb.get(date, 0) + size_gb
                    except:
                        pass
                
                stats['daily_storage'] = [{'date': d, 'gb': round(g, 2)} for d, g in sorted(daily_gb.items())]
                
                # Top 10 most cached files with actual sizes
                rows = conn.execute('''
                    SELECT filename, COUNT(*) as count, details
                    FROM activity_log
                    WHERE action = 'copy' AND filename IS NOT NULL
                    GROUP BY filename
                    ORDER BY count DESC
                    LIMIT 10
                ''').fetchall()
                
                top_files = []
                for r in rows:
                    # Parse size from most recent details
                    details = r['details'] or ''
                    size_gb = 0
                    try:
                        if 'Size:' in details:
                            size_str = details.split('Size:')[1].strip().split()[0]
                            size_gb = float(size_str)
                    except:
                        pass
                    top_files.append({
                        'filename': r['filename'],
                        'count': r['count'],
                        'total_gb': round(size_gb * r['count'], 2)
                    })
                stats['top_files'] = top_files
                
        except Exception as e:
            logger.error(f"Statistics error: {e}")
        
        return stats
    
    def clear_all(self):
        with self._conn() as conn:
            conn.execute("DELETE FROM managed_files")
            conn.execute("DELETE FROM cleanup_queue")
    
    def reset_activity_log(self):
        """Clear activity log and reset statistics counters"""
        with self._conn() as conn:
            conn.execute("DELETE FROM activity_log")
            conn.execute("UPDATE stats SET value = '0' WHERE key = 'total_moves'")
            conn.execute("UPDATE stats SET value = '0.0' WHERE key = 'total_gb_moved'")
            conn.execute("UPDATE stats SET value = '' WHERE key = 'last_move_date'")
        logger.info("Activity log and statistics reset")

DB = Database()

# ============================================
# PATH TOOLS (PRESERVED FROM v2.22d)
# ============================================

class PathTools:
    @staticmethod
    def map_path(p):
        p = str(p)
        for d, h in Config.PATH_MAP.items():
            if p.startswith(d):
                return Path(p.replace(d, h, 1))
        return Path(p)
    
    @staticmethod
    def get_cache(p):
        s = str(p)
        if s.startswith(Config.C["UNRAID_USER_PATH"]):
            return Path(s.replace(Config.C["UNRAID_USER_PATH"], Config.C["CACHE_PATH"], 1))
        return None
    
    @staticmethod
    def get_array(p):
        s = str(p)
        if s.startswith(Config.C["UNRAID_USER_PATH"]):
            return Path(s.replace(Config.C["UNRAID_USER_PATH"], Config.C["ARRAY_ONLY_PATH"], 1))
        return None
    
    @staticmethod
    def get_user(p):
        s = str(p)
        if s.startswith(Config.C["CACHE_PATH"]):
            return Path(s.replace(Config.C["CACHE_PATH"], Config.C["UNRAID_USER_PATH"], 1))
        if s.startswith(Config.C["ARRAY_ONLY_PATH"]):
            return Path(s.replace(Config.C["ARRAY_ONLY_PATH"], Config.C["UNRAID_USER_PATH"], 1))
        return Path(p)

# ============================================
# MOVER IGNORE MANAGEMENT
# ============================================

class MoverIgnore:
    LOCK = threading.Lock()
    
    @staticmethod
    def add(path):
        f = Config.C["MOVER_IGNORE_FILE"]
        if not f:
            return
        user_path = str(PathTools.get_user(path))
        try:
            with MoverIgnore.LOCK:
                lines = set()
                if os.path.exists(f):
                    with open(f, 'r') as fp:
                        lines = set(l.strip() for l in fp if l.strip())
                if user_path not in lines:
                    with open(f, 'a') as fp:
                        fp.write(user_path + "\n")
                    logger.info(f"MoverIgnore added: {user_path}")
        except Exception as e:
            logger.error(f"MoverIgnore.add error: {e}")
    
    @staticmethod
    def remove(path):
        f = Config.C["MOVER_IGNORE_FILE"]
        if not f or not os.path.exists(f):
            return
        user_path = str(PathTools.get_user(path))
        try:
            with MoverIgnore.LOCK:
                with open(f, 'r') as fp:
                    lines = [l.strip() for l in fp if l.strip()]
                if user_path in lines:
                    with open(f, 'w') as fp:
                        for l in lines:
                            if l != user_path:
                                fp.write(l + "\n")
                    logger.info(f"MoverIgnore removed: {user_path}")
        except Exception as e:
            logger.error(f"MoverIgnore.remove error: {e}")
    
    @staticmethod
    def get_content():
        f = Config.C["MOVER_IGNORE_FILE"]
        if f and os.path.exists(f):
            try:
                with open(f, 'r') as fp:
                    return fp.read()
            except:
                pass
        return ""

# ============================================
# NOTIFICATION MANAGER
# ============================================

class Notify:
    COLORS = {
        "GREEN": 5763719,
        "YELLOW": 16776960,
        "ORANGE": 15105570,
        "RED": 15548997,
        "GREY": 9807270
    }
    
    def send(self, title, desc, color):
        url = Config.C["DISCORD_WEBHOOK_URL"]
        if not url:
            return
        data = {
            "embeds": [{
                "title": title,
                "description": desc,
                "color": color,
                "footer": {"text": "Emby Smart Cache V3.0"},
                "timestamp": datetime.utcnow().strftime("%Y-%m-%dT%H:%M:%S.000Z")
            }]
        }
        try:
            req = urllib.request.Request(
                url,
                data=json.dumps(data).encode(),
                headers={'Content-Type': 'application/json', 'User-Agent': 'Mozilla/5.0'}
            )
            with urllib.request.urlopen(req, timeout=10):
                pass
        except Exception as e:
            logger.error(f"Discord notification error: {e}")

NOTIFY = Notify()

# ============================================
# CACHE MANAGER (CORE LOGIC PRESERVED)
# ============================================

class CacheManager:
    def __init__(self):
        self.lock = threading.Lock()
        self.active = set()
        self.active_lock = threading.Lock()
        self.processed = set()
        self.processed_lock = threading.Lock()
        self._cleanup_partials()
        self._recover_state()
    
    def _cleanup_partials(self):
        """Remove orphaned .partial files"""
        try:
            cache = Config.C["CACHE_PATH"]
            if not os.path.exists(cache):
                return
            for p in Path(cache).rglob("*" + Config.PARTIAL_SUFFIX):
                try:
                    if time.time() - p.stat().st_mtime > 3600:
                        p.unlink()
                        logger.info(f"Removed orphan partial: {p.name}")
                except:
                    pass
        except Exception as e:
            logger.error(f"Partial cleanup error: {e}")
    
    def _recover_state(self):
        """Scan for .moved_to_cache files and rebuild database state"""
        logger.info("State recovery starting...")
        logger.debug(f"Scanning array path: {Config.C['ARRAY_ONLY_PATH']}")
        count = 0
        try:
            array_path = Config.C["ARRAY_ONLY_PATH"]
            if not os.path.exists(array_path):
                logger.warning(f"Array path does not exist: {array_path}")
                return
            
            for hidden in Path(array_path).rglob("*" + Config.HIDDEN_SUFFIX):
                try:
                    logger.debug(f"Found marker: {hidden}")
                    base = hidden.name.replace(Config.HIDDEN_SUFFIX, "")
                    if Path(base).suffix.lower() in Config.ALLOWED_SUB_EXTS:
                        logger.debug(f"Skipping subtitle: {base}")
                        continue
                    
                    arr_orig = hidden.with_name(base)
                    user_path = PathTools.get_user(arr_orig)
                    cache_path = PathTools.get_cache(user_path)
                    
                    logger.debug(f"Paths: arr={arr_orig}, user={user_path}, cache={cache_path}")
                    
                    if not cache_path or not cache_path.exists():
                        logger.debug(f"Cache file missing: {cache_path}")
                        continue
                    
                    # Verify cache file integrity
                    size = cache_path.stat().st_size if cache_path.exists() else 0
                    if size == 0:
                        logger.warning(f"Cache file is empty: {cache_path}")
                        continue
                    
                    # Add to database and mover ignore (don't log as 'copy' - this is recovery)
                    DB.add_managed_file(user_path, cache_path, arr_orig, base, size, log_action=None)
                    MoverIgnore.add(user_path)
                    count += 1
                    logger.info(f"Recovered: {base}")
                    logger.debug(f"Recovered file size: {size / (2**30):.2f} GB")
                    
                except Exception as e:
                    logger.error(f"Recovery error for {hidden}: {e}")
            
            if count:
                logger.info(f"State recovery complete: {count} files recovered")
                NOTIFY.send("State Recovered", f"Found {count} managed files", NOTIFY.COLORS["GREEN"])
            else:
                logger.info("State recovery complete: no files found")
                
        except Exception as e:
            logger.error(f"State recovery error: {e}")
    
    def force_cleanup(self, user_path_str):
        """Force immediate cleanup of a cached file.
        
        CRITICAL SAFETY: This function checks for the ownership marker
        before deleting ANY file. If the marker (.moved_to_cache) does not
        exist on the array, the file is a NATIVE CACHE file and we must NOT
        delete it.
        """
        logger.info(f"Force cleanup requested: {user_path_str}")
        logger.debug(f"CACHE_PATH: {Config.C['CACHE_PATH']}")
        logger.debug(f"UNRAID_USER_PATH: {Config.C['UNRAID_USER_PATH']}")
        
        try:
            # Normalize path
            if user_path_str.startswith(Config.C["CACHE_PATH"]):
                user_path_str = user_path_str.replace(Config.C["CACHE_PATH"], Config.C["UNRAID_USER_PATH"])
                logger.debug(f"Path normalized from cache to user path")
            
            user_path = Path(user_path_str)
            logger.info(f"Normalized user_path: {user_path}")
            
            cache = PathTools.get_cache(user_path)
            arr = PathTools.get_array(user_path)
            logger.info(f"Cache path: {cache}")
            logger.info(f"Array path: {arr}")
            logger.debug(f"Cache exists: {cache.exists() if cache else False}")
            logger.debug(f"Array exists: {arr.exists() if arr else False}")
            
            # ============================================
            # CRITICAL SAFETY CHECK: Ownership Verification
            # ============================================
            if arr:
                hidden = arr.with_name(arr.name + Config.HIDDEN_SUFFIX)
                if not hidden.exists():
                    # NO MARKER = NATIVE CACHE FILE = DO NOT DELETE!
                    logger.warning(f"BLOCKED: Attempted force cleanup on NATIVE cache file (no marker): {user_path.name}")
                    logger.warning(f"  Expected marker at: {hidden}")
                    logger.warning(f"  This file was not moved by Emby Smart Cache. Cleanup aborted.")
                    return {'success': False, 'error': 'Cannot cleanup: This is a native cache file, not managed by Emby Smart Cache.'}
            else:
                logger.warning(f"BLOCKED: Cannot determine array path for: {user_path_str}")
                return {'success': False, 'error': 'Cannot determine array path'}
            
            # Marker exists - this is our managed file, safe to proceed
            logger.info(f"Ownership verified (marker exists): {hidden}")
            
            # Remove from queue and database
            logger.info("Removing from cleanup queue...")
            try:
                DB.remove_from_queue(user_path)
                logger.info("Removed from cleanup queue")
            except Exception as e:
                logger.error(f"Error removing from queue: {e}")
            
            logger.info("Removing from managed files...")
            try:
                DB.remove_managed_file(user_path)
                logger.info("Removed from managed files")
            except Exception as e:
                logger.error(f"Error removing from managed files: {e}")
            
            # Remove from mover ignore
            logger.info("Removing from mover ignore...")
            try:
                MoverIgnore.remove(user_path)
                logger.info("Removed from mover ignore")
            except Exception as e:
                logger.error(f"Error removing from mover ignore: {e}")
            
            # Restore hidden array file
            logger.info(f"Restoring hidden file: {hidden} -> {arr}")
            try:
                if hidden.exists():
                    os.rename(str(hidden), str(arr))
                    logger.info(f"Restored: {arr.name}")
                else:
                    logger.warning(f"Hidden file does not exist: {hidden}")
            except Exception as e:
                logger.error(f"Restore error: {e}")
            
            # Also restore subtitle files
            logger.info("Restoring subtitle files...")
            try:
                stem = arr.stem
                for f in arr.parent.iterdir():
                    if f.name.startswith(stem) and f.name.endswith(Config.HIDDEN_SUFFIX):
                        try:
                            orig_name = f.name[:-len(Config.HIDDEN_SUFFIX)]
                            orig = f.with_name(orig_name)
                            os.rename(str(f), str(orig))
                            logger.info(f"Restored subtitle: {orig_name}")
                            try:
                                MoverIgnore.remove(PathTools.get_user(orig))
                            except:
                                pass
                        except Exception as e:
                            logger.error(f"Subtitle restore error: {e}")
            except Exception as e:
                logger.error(f"Subtitle glob error: {e}")
            
            # Delete cache copy (NOW SAFE - we verified ownership)
            logger.info(f"Deleting cache copy: {cache}")
            if cache and cache.exists():
                try:
                    os.remove(str(cache))
                    logger.info(f"Deleted cache copy: {cache.name}")
                except Exception as e:
                    logger.error(f"Delete error: {e}")
                
                # Also delete cached subtitles
                logger.info("Deleting cached subtitles...")
                try:
                    stem = cache.stem
                    for f in cache.parent.iterdir():
                        if f.name.startswith(stem) and f.suffix.lower() in Config.ALLOWED_SUB_EXTS:
                            try:
                                os.remove(str(f))
                                logger.info(f"Deleted cached subtitle: {f.name}")
                                try:
                                    MoverIgnore.remove(PathTools.get_user(f))
                                except:
                                    pass
                            except Exception as e:
                                logger.error(f"Subtitle delete error: {e}")
                except Exception as e:
                    logger.error(f"Subtitle cleanup error: {e}")
            else:
                logger.warning(f"Cache file does not exist: {cache}")
            
            logger.info(f"Force cleanup complete: {user_path.name}")
            NOTIFY.send("Cleanup Complete", user_path.name, NOTIFY.COLORS["GREY"])
            return {'success': True, 'message': f'Cleanup complete: {user_path.name}'}
            
        except Exception as e:
            logger.error(f"Force cleanup failed with exception: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return {'success': False, 'error': str(e)}
    
    def copy_file(self, path, item_id=None):
        """Copy a file to cache (main caching logic)"""
        logger.debug(f"copy_file called: path={path}, item_id={item_id}")
        
        if not Config.C["ENABLED"]:
            logger.debug("Plugin disabled, skipping")
            return
        
        # Check exclusions
        for ex in Config.EXCLUDE_LIST:
            if ex and ex in str(path):
                logger.debug(f"Path excluded by rule: {ex}")
                return
        
        # Check extension
        if path.suffix.lower() not in Config.ALLOWED_EXTS_SET:
            logger.debug(f"Extension not allowed: {path.suffix}")
            return
        
        # Check for parity operation
        try:
            with open("/proc/mdstat", "r") as f:
                if "resync" in f.read():
                    NOTIFY.send("System Busy", f"Parity check. Skip: {path.name}", NOTIFY.COLORS["ORANGE"])
                    logger.debug("Parity check in progress, skipping")
                    return
        except:
            pass
        
        arr = PathTools.get_array(path)
        cache = PathTools.get_cache(path)
        
        logger.debug(f"Computed paths: arr={arr}, cache={cache}")
        
        if not arr or not cache:
            logger.debug("Could not compute array or cache path")
            return
        
        # SAFETY: Validate cache path before any file operations
        if not Config.validate_path(str(cache)):
            logger.critical(f"CRITICAL: Invalid cache path: {cache}")
            logger.critical("This path could write to RAM! Aborting.")
            return
        
        # CRITICAL: Check hardlinks on ARRAY path, not user path
        if Config.C["SKIP_HARDLINKS"] and arr.exists():
            try:
                nlink = arr.stat().st_nlink
                if nlink > 1:
                    NOTIFY.send("Hardlink Skip", f"{path.name} ({nlink} links)", NOTIFY.COLORS["GREY"])
                    logger.info(f"SKIP hardlink: {path.name} has {nlink} links")
                    return
            except:
                pass
        
        # Remove from cleanup queue if re-playing
        if DB.remove_from_queue(path):
            NOTIFY.send("Resumed", path.name, NOTIFY.COLORS["GREEN"])
        
        # Check if already processed this session
        with self.processed_lock:
            if item_id:
                if item_id in self.processed:
                    return
                self.processed.add(item_id)
        
        # Get size from array file
        size_bytes = arr.stat().st_size if arr.exists() else 0
        size_gb = size_bytes / (2**30)
        
        # Check max file size
        if Config.C["MAX_FILE_SIZE_GB"] > 0 and size_gb > Config.C["MAX_FILE_SIZE_GB"]:
            logger.info(f"SKIP: Too large ({size_gb:.1f} GB > {Config.C['MAX_FILE_SIZE_GB']} GB)")
            return
        
        hidden = arr.with_name(arr.name + Config.HIDDEN_SUFFIX)
        
        # Check if already cached
        if cache.exists():
            if hidden.exists():
                # Managed cached file
                MoverIgnore.add(path)
                if not DB.is_managed(path):
                    # Re-add to database (don't log as new copy)
                    DB.add_managed_file(path, cache, arr, path.name, size_bytes, log_action=None)
                NOTIFY.send("Playing (Cached)", path.name, NOTIFY.COLORS["GREEN"])
            else:
                # Native cache file
                NOTIFY.send("Native Cache", f"Ignoring: {path.name}", NOTIFY.COLORS["GREY"])
            return
        
        # Check if source exists
        if not arr.exists():
            logger.warning(f"Source not found: {arr}")
            return
        
        # Check free space
        try:
            _, _, free = shutil.disk_usage(Config.C["CACHE_PATH"])
            required = Config.C["MIN_FREE_SPACE_GB"] + size_gb
            if (free / (2**30)) < required:
                NOTIFY.send("No Space", f"Skip: {path.name}", NOTIFY.COLORS["RED"])
                return
        except:
            pass
        
        # Mark as active
        with self.active_lock:
            if str(path) in self.active:
                return
            self.active.add(str(path))
        
        NOTIFY.send("Caching", f"{path.name} ({size_gb:.1f} GB)", NOTIFY.COLORS["YELLOW"])
        logger.info(f"Starting cache copy: {path.name}")
        
        # Start worker thread
        threading.Thread(
            target=self._worker,
            args=(path, cache, arr, size_bytes, size_gb),
            daemon=True
        ).start()
    
    def _worker(self, user_path, cache, arr, size_bytes, size_gb):
        """Worker thread for file copy operation (ATOMIC SWAP with ROLLBACK)"""
        tmp = cache.with_name(cache.name + Config.PARTIAL_SUFFIX)
        hidden = arr.with_name(arr.name + Config.HIDDEN_SUFFIX)
        start_time = time.time()
        max_retries = Config.C.get("RSYNC_RETRIES", 3)
        
        try:
            # Create cache directory
            cache.parent.mkdir(parents=True, exist_ok=True)
            
            # Copy subtitles first
            try:
                for f in arr.parent.glob(glob.escape(arr.stem) + "*"):
                    if f.suffix.lower() in Config.ALLOWED_SUB_EXTS:
                        sub_dst = cache.with_name(f.name)
                        if not sub_dst.exists():
                            subprocess.run(["rsync", "-a", str(f), str(sub_dst)], 
                                         check=False, capture_output=True)
            except:
                pass
            
            # Main file copy via rsync WITH RETRY
            rsync_success = False
            last_error = ""
            
            for attempt in range(1, max_retries + 1):
                logger.info(f"Rsync attempt {attempt}/{max_retries}: {user_path.name}")
                
                cmd = [
                    "rsync", "-a", "--inplace", "--progress",
                    f"--bwlimit={Config.C['RSYNC_BWLIMIT']}",
                    str(arr), str(tmp)
                ]
                
                try:
                    res = subprocess.run(cmd, capture_output=True, text=True, timeout=3600)  # 1 hour timeout
                    
                    if res.returncode == 0:
                        rsync_success = True
                        break
                    else:
                        last_error = res.stderr or f"Exit code {res.returncode}"
                        logger.warning(f"Rsync attempt {attempt} failed: {last_error}")
                        
                except subprocess.TimeoutExpired:
                    last_error = "Timeout (1 hour exceeded)"
                    logger.warning(f"Rsync attempt {attempt} timed out")
                except Exception as e:
                    last_error = str(e)
                    logger.warning(f"Rsync attempt {attempt} exception: {e}")
                
                # Clean up failed attempt
                if tmp.exists():
                    try:
                        tmp.unlink()
                    except:
                        pass
                
                # Wait before retry (exponential backoff)
                if attempt < max_retries:
                    wait_time = 2 ** attempt
                    logger.info(f"Waiting {wait_time}s before retry...")
                    time.sleep(wait_time)
            
            if not rsync_success:
                logger.error(f"Rsync failed after {max_retries} attempts: {last_error}")
                NOTIFY.send("Copy Failed", f"{user_path.name}: {last_error[:30]}", NOTIFY.COLORS["RED"])
                return
            
            # Calculate speed
            elapsed = time.time() - start_time
            speed_mbps = (size_bytes / (1024 * 1024)) / elapsed if elapsed > 0 else 0
            
            # Set permissions
            try:
                os.chmod(tmp, 0o666)
                shutil.chown(tmp, "nobody", "users")
            except:
                pass
            
            # ATOMIC SWAP WITH ROLLBACK
            try:
                # Step 1: Hide original
                os.rename(arr, hidden)
                
                # Step 2: Move partial to final (if this fails, rollback)
                try:
                    os.rename(tmp, cache)
                except Exception as e:
                    # ROLLBACK: Restore hidden file
                    logger.error(f"Rename failed, rolling back: {e}")
                    NOTIFY.send("Swap Failed", f"{user_path.name}: Rolling back", NOTIFY.COLORS["RED"])
                    if hidden.exists():
                        os.rename(hidden, arr)
                    if tmp.exists():
                        tmp.unlink()
                    raise
                    
            except Exception as e:
                logger.error(f"Atomic swap failed: {e}")
                return
            
            # Hide subtitle files too
            try:
                for f in arr.parent.glob(glob.escape(arr.stem) + "*"):
                    if f.suffix.lower() in Config.ALLOWED_SUB_EXTS:
                        sub_hid = f.with_name(f.name + Config.HIDDEN_SUFFIX)
                        try:
                            os.rename(f, sub_hid)
                            MoverIgnore.add(PathTools.get_user(cache.with_name(f.name)))
                        except:
                            pass
            except:
                pass
            
            # Add to mover ignore and database
            MoverIgnore.add(user_path)
            DB.add_managed_file(user_path, cache, arr, user_path.name, size_bytes)
            DB.update_stats(user_path.name, size_gb)
            
            # Success notification with speed
            NOTIFY.send("Cached", f"{user_path.name} ({size_gb:.1f}GB in {elapsed:.0f}s @ {speed_mbps:.1f}MB/s)", NOTIFY.COLORS["GREEN"])
            logger.info(f"Cache complete: {user_path.name} - {size_gb:.1f}GB in {elapsed:.0f}s ({speed_mbps:.1f} MB/s)")
            
        except Exception as e:
            logger.error(f"Worker error: {e}")
            NOTIFY.send("Cache Error", f"{user_path.name}: {str(e)[:30]}", NOTIFY.COLORS["RED"])
            if tmp.exists():
                try:
                    tmp.unlink()
                except:
                    pass
        finally:
            with self.active_lock:
                self.active.discard(str(user_path))
    
    def schedule_cleanup(self, path):
        """Schedule a file for cleanup after playback stops"""
        if not Config.C["DELETE_ON_STOP"]:
            return
        
        arr = PathTools.get_array(path)
        if arr:
            hidden = arr.with_name(arr.name + Config.HIDDEN_SUFFIX)
            if not hidden.exists():
                # This is a native cache file, not our managed file
                logger.info(f"Not scheduling (native cache): {path.name}")
                return
        
        delay = Config.C["CLEANUP_DELAY_HOURS"]
        DB.schedule_cleanup(path, path.name, delay)
        NOTIFY.send("Stopped", f"Cleanup in {delay}h: {path.name}", NOTIFY.COLORS["GREY"])
        logger.info(f"Scheduled cleanup: {path.name} in {delay}h")
    
    def process_queue(self):
        """Process pending cleanup queue"""
        for item in DB.get_pending_cleanups():
            try:
                logger.info(f"Processing scheduled cleanup: {item['filename']}")
                self.force_cleanup(item['user_path'])
            except Exception as e:
                logger.error(f"Queue processing error: {e}")
    
    def is_cached(self, path):
        """Check if a file is currently cached"""
        cache = PathTools.get_cache(path)
        return cache and cache.exists()
    
    def get_active(self):
        """Get list of currently active transfers"""
        with self.active_lock:
            return list(self.active)

CM = CacheManager()

# ============================================
# PLAYBACK MONITOR
# ============================================

class Monitor:
    def __init__(self):
        self.active = set()
        self.lock = threading.Lock()
        self.headers = {
            "X-Emby-Token": Config.C["EMBY_API_KEY"],
            "Content-Type": "application/json"
        }
    
    def start(self, item_id, item_type):
        with self.lock:
            if item_id in self.active:
                return
            self.active.add(item_id)
        threading.Thread(target=self._run, args=(item_id, item_type), daemon=True).start()
    
    def _request(self, endpoint, retries=3):
        url = urljoin(Config.C["EMBY_HOST"], endpoint)
        for i in range(retries):
            try:
                req = urllib.request.Request(url, headers=self.headers)
                with urllib.request.urlopen(req, timeout=10) as r:
                    return json.loads(r.read().decode())
            except:
                if i < retries - 1:
                    time.sleep(2 ** i)
        return None
    
    def _run(self, item_id, item_type):
        logger.info(f"Monitor started: {item_id} ({item_type})")
        logger.debug(f"Cooldown: Movie={Config.C['COOLDOWN_MOVIE_SEC']}s, Episode={Config.C['COOLDOWN_EPISODE_SEC']}s")
        session = None
        
        # Find the session
        for _ in range(5):
            sessions = self._request("/Sessions")
            if sessions:
                session = next(
                    (s for s in sessions 
                     if "NowPlayingItem" in s and s["NowPlayingItem"].get("Id") == item_id),
                    None
                )
                if session:
                    break
            time.sleep(1)
        
        if not session:
            logger.debug(f"Session not found for {item_id}")
            with self.lock:
                self.active.discard(item_id)
            return
        
        item = session["NowPlayingItem"]
        path = PathTools.map_path(item.get("Path", ""))
        user_id = session.get('UserId')
        series_id = item.get("SeriesId")
        
        logger.debug(f"Monitoring: {path.name if hasattr(path, 'name') else path}")
        
        # If already cached, just trigger copy_file (handles mover ignore etc) and return
        if CM.is_cached(path):
            logger.info(f"Already cached, skipping cooldown: {path.name if hasattr(path, 'name') else path}")
            CM.copy_file(path, item_id)
            with self.lock:
                self.active.discard(item_id)
            return
        
        # Wait for cooldown threshold BEFORE caching anything
        cooldown = Config.C["COOLDOWN_MOVIE_SEC"] if item_type == "Movie" else Config.C["COOLDOWN_EPISODE_SEC"]
        logger.info(f"Waiting for {cooldown}s cooldown before caching")
        
        cooldown_reached = False
        while True:
            sessions = self._request("/Sessions")
            if not sessions:
                time.sleep(10)
                continue
            
            session = next(
                (s for s in sessions 
                 if "NowPlayingItem" in s and s["NowPlayingItem"].get("Id") == item_id),
                None
            )
            
            if not session:
                logger.debug("Session ended before cooldown reached")
                break
            
            ps = session.get("PlayState", {})
            if ps.get("IsPaused"):
                logger.debug("Playback paused, waiting...")
                time.sleep(10)
                continue
            
            position_sec = ps.get("PositionTicks", 0) / 10000000
            logger.debug(f"Position: {position_sec:.0f}s / Cooldown: {cooldown}s")
            
            if position_sec >= cooldown:
                logger.info(f"Cooldown reached ({position_sec:.0f}s >= {cooldown}s), starting cache")
                cooldown_reached = True
                
                # Now cache the current file
                CM.copy_file(path, item_id)
                
                # Pre-fetch next episodes for TV shows (AFTER cooldown is reached)
                if item_type == "Episode" and Config.C["PRECACHE_EPISODES"] > 0:
                    self._precache_next_episodes(user_id, series_id, Config.C["PRECACHE_EPISODES"])
                
                break
            
            time.sleep(10)
        
        with self.lock:
            self.active.discard(item_id)
    
    def _precache_next_episodes(self, user_id, series_id, count):
        """Pre-cache the next N episodes in the series"""
        if not user_id or not series_id:
            return
        
        try:
            result = self._request(f"/Shows/NextUp?UserId={user_id}&SeriesId={series_id}&Limit={count}&Fields=Path")
            if result and "Items" in result:
                for i, n in enumerate(result["Items"]):
                    if n.get("Path"):
                        next_path = PathTools.map_path(n["Path"])
                        logger.info(f"Pre-caching next episode {i+1}/{count}: {n.get('Name', next_path.name if hasattr(next_path, 'name') else next_path)}")
                        CM.copy_file(next_path)
        except Exception as e:
            logger.error(f"Pre-cache error: {e}")
            NOTIFY.send("Pre-cache Error", str(e)[:50], NOTIFY.COLORS["RED"])

MON = Monitor()

# ============================================
# HTTP API HANDLER
# ============================================

class Handler(BaseHTTPRequestHandler):
    def log_message(self, *args):
        pass  # Suppress default logging
    
    def _send_json(self, data, status=200):
        self.send_response(status)
        self.send_header('Content-Type', 'application/json')
        self.send_header('Access-Control-Allow-Origin', '*')
        self.end_headers()
        self.wfile.write(json.dumps(data).encode())
    
    def _get_health_data(self):
        """Get system health metrics"""
        health = {}
        try:
            # Cache disk usage
            cache_path = Config.C.get('CACHE_PATH', '/mnt/cache_data')
            if os.path.exists(cache_path):
                stat = os.statvfs(cache_path)
                total = stat.f_blocks * stat.f_frsize
                free = stat.f_bavail * stat.f_frsize
                used = total - free
                health['cache_total_gb'] = total / (2**30)
                health['cache_used_gb'] = used / (2**30)
                health['cache_free_gb'] = free / (2**30)
                health['cache_used_pct'] = (used / total * 100) if total > 0 else 0
            
            # Array disk usage
            array_path = Config.C.get('ARRAY_ONLY_PATH', '/mnt/user0')
            if os.path.exists(array_path):
                stat = os.statvfs(array_path)
                total = stat.f_blocks * stat.f_frsize
                free = stat.f_bavail * stat.f_frsize
                used = total - free
                health['array_total_gb'] = total / (2**30)
                health['array_used_gb'] = used / (2**30)
                health['array_free_gb'] = free / (2**30)
                health['array_used_pct'] = (used / total * 100) if total > 0 else 0
            
            # Database size
            db_path = os.path.join(Config.DATA_DIR, Config.DB_FILE)
            if os.path.exists(db_path):
                size = os.path.getsize(db_path)
                if size < 1024:
                    health['db_size'] = f"{size} B"
                elif size < 1024 * 1024:
                    health['db_size'] = f"{size/1024:.1f} KB"
                else:
                    health['db_size'] = f"{size/(1024*1024):.1f} MB"
            else:
                health['db_size'] = '-'
            
            # Log file size
            log_path = Config.C.get('LOG_FILE_PATH', '')
            if log_path and os.path.exists(log_path):
                size = os.path.getsize(log_path)
                if size < 1024:
                    health['log_size'] = f"{size} B"
                elif size < 1024 * 1024:
                    health['log_size'] = f"{size/1024:.1f} KB"
                else:
                    health['log_size'] = f"{size/(1024*1024):.1f} MB"
            else:
                health['log_size'] = '-'
                
        except Exception as e:
            logger.error(f"Health check error: {e}")
        
        return health
    
    def do_GET(self):
        parsed = urlparse(self.path)
        path = parsed.path
        query = parse_qs(parsed.query)
        
        try:
            if path == '/api/status':
                stats = DB.get_stats()
                self._send_json({
                    'success': True,
                    'data': {
                        'running': True,
                        'uptime': time.time() - START_TIME,
                        'active': CM.get_active(),
                        'active_count': len(CM.get_active()),
                        'queue_count': stats.get('queue_count', 0),
                        'managed_count': stats.get('managed_count', 0),
                        'total_gb': stats.get('total_cached_bytes', 0) / (2**30),
                        'total_moves': int(stats.get('total_moves', 0)),
                        'total_gb_moved': float(stats.get('total_gb_moved', 0))
                    }
                })
            
            elif path == '/api/managed':
                files = DB.get_managed_files()
                result = []
                for f in files:
                    result.append({
                        'path': f['user_path'],
                        'filename': f['filename'],
                        'size_gb': (f['size_bytes'] or 0) / (2**30),
                        'cached_at': f['cached_at'],
                        'cleanup_at': f.get('cleanup_at')
                    })
                self._send_json({'success': True, 'data': result})
            
            elif path == '/api/queue':
                queue = DB.get_cleanup_queue()
                result = []
                for q in queue:
                    result.append({
                        'path': q['user_path'],
                        'filename': q['filename'],
                        'scheduled_at': q['scheduled_at'],
                        'cleanup_time': float(q.get('cleanup_time_unix', 0))
                    })
                self._send_json({'success': True, 'data': result})
            
            elif path == '/api/logs':
                lines = int(query.get('lines', [100])[0])
                log_content = ""
                if os.path.exists(LOG_FILE):
                    try:
                        result = subprocess.run(
                            ['tail', '-n', str(lines), LOG_FILE],
                            capture_output=True, text=True
                        )
                        log_content = result.stdout
                    except:
                        with open(LOG_FILE, 'r') as f:
                            log_content = '\n'.join(f.readlines()[-lines:])
                self._send_json({'success': True, 'logs': log_content})
            
            elif path == '/api/mover_ignore':
                self._send_json({'success': True, 'content': MoverIgnore.get_content()})
            
            elif path == '/api/history':
                activity = DB.get_activity(50)
                self._send_json({'success': True, 'data': activity})
            
            elif path == '/api/health':
                health = self._get_health_data()
                self._send_json({'success': True, 'data': health})
            
            elif path == '/api/stats':
                stats = DB.get_statistics()
                self._send_json({'success': True, 'data': stats})
            
            else:
                self._send_json({'success': False, 'error': 'Unknown endpoint'}, 404)
                
        except Exception as e:
            logger.error(f"GET error: {e}")
            self._send_json({'success': False, 'error': str(e)}, 500)
    
    def do_POST(self):
        try:
            length = int(self.headers.get('content-length', 0))
            data = {}
            if length > 0:
                try:
                    data = json.loads(self.rfile.read(length).decode())
                except:
                    pass
            
            parsed = urlparse(self.path)
            path = parsed.path
            
            if path == '/api/cleanup':
                if data.get('path'):
                    result = CM.force_cleanup(data['path'])
                    if isinstance(result, dict):
                        self._send_json(result)
                    else:
                        self._send_json({'success': True, 'message': 'Cleanup complete'})
                else:
                    self._send_json({'success': False, 'error': 'No path specified'}, 400)
            
            elif path == '/api/rebuild':
                DB.clear_all()
                CM._recover_state()
                self._send_json({'success': True, 'message': 'State rebuilt successfully'})
            
            elif path == '/api/reset_stats':
                DB.reset_activity_log()
                self._send_json({'success': True, 'message': 'Statistics reset successfully'})
            
            elif path == '/api/get_queue':
                # Legacy endpoint compatibility
                queue_dict = {}
                for q in DB.get_cleanup_queue():
                    queue_dict[q['user_path']] = float(q.get('cleanup_time_unix', 0))
                self._send_json({'success': True, 'message': queue_dict})
            
            elif path == '/api/force_cleanup':
                # Legacy endpoint compatibility
                if data.get('path'):
                    result = CM.force_cleanup(data['path'])
                    if isinstance(result, dict):
                        self._send_json(result)
                    else:
                        self._send_json({'success': True, 'message': 'Cleanup executed'})
                else:
                    self._send_json({'success': False, 'error': 'No path'}, 400)
            
            elif path == '/api/rebuild_state':
                # Legacy endpoint compatibility
                DB.clear_all()
                CM._recover_state()
                self._send_json({'success': True, 'message': 'State rebuild complete'})
            
            else:
                # Emby webhook handler
                event = data.get("Event")
                item = data.get("Item", {})
                
                logger.debug(f"WEBHOOK received: event={event}, item_type={item.get('Type')}, item_name={item.get('Name')}")
                
                if event == "playback.start" and item.get("Type") in ["Movie", "Episode"]:
                    logger.info(f"WEBHOOK: Playback start - {item.get('Name')}")
                    logger.debug(f"Item details: Id={item.get('Id')}, Path={item.get('Path')}")
                    MON.start(item.get("Id"), item.get("Type"))
                
                elif event == "playback.stop" and item.get("Path"):
                    path = PathTools.map_path(item["Path"])
                    logger.info(f"WEBHOOK: Playback stop - {item.get('Name')}")
                    logger.debug(f"Mapped path: {path}")
                    CM.schedule_cleanup(path)
                
                self._send_json({'success': True, 'message': 'OK'})
                
        except Exception as e:
            logger.error(f"POST error: {e}")
            self._send_json({'success': False, 'error': str(e)}, 500)

# ============================================
# MAIN
# ============================================

shutdown_event = threading.Event()

def signal_handler(signum, frame):
    logger.info(f"Received signal {signum}, shutting down...")
    shutdown_event.set()

def maintenance_loop():
    """Background maintenance loop - runs every 5 minutes"""
    while not shutdown_event.is_set():
        try:
            CM.process_queue()
        except Exception as e:
            logger.error(f"Maintenance error: {e}")
        
        # Sleep for 5 minutes (300 seconds) in small intervals
        for _ in range(300):
            if shutdown_event.is_set():
                break
            time.sleep(1)

def main():
    signal.signal(signal.SIGTERM, signal_handler)
    signal.signal(signal.SIGINT, signal_handler)
    
    # Reload config
    Config.load()
    
    # Log configuration for debugging
    logger.info("=" * 50)
    logger.info("Emby Smart Cache v3.2.0 starting...")
    logger.info(f"CACHE_PATH: {Config.C['CACHE_PATH']}")
    logger.info(f"ARRAY_ONLY_PATH: {Config.C['ARRAY_ONLY_PATH']}")
    logger.info(f"SERVER_PORT: {Config.C['SERVER_PORT']}")
    logger.info(f"LOG_LEVEL: {Config.C.get('LOG_LEVEL', 'INFO')}")
    
    # SAFETY: Validate critical paths at startup
    cache_path = Config.C["CACHE_PATH"]
    if not Config.validate_path(cache_path):
        logger.critical(f"CRITICAL: CACHE_PATH '{cache_path}' is not a valid Unraid mount!")
        logger.critical("This could write to RAM and fill it up. Please fix settings.json")
        logger.critical("Valid paths start with: /mnt/user, /mnt/cache, /mnt/disk, /mnt/user0, /mnt/remotes")
        sys.exit(1)
    else:
        logger.info(f"Path validation passed for: {cache_path}")
    
    # Start maintenance thread
    maint_thread = threading.Thread(target=maintenance_loop, daemon=True)
    maint_thread.start()
    
    port = Config.C["SERVER_PORT"]
    logger.info(f"Starting HTTP server on port {port}...")
    NOTIFY.send("Started", f"v3.2.0 on port {port}", NOTIFY.COLORS["GREEN"])
    
    try:
        server = ThreadingHTTPServer(('0.0.0.0', port), Handler)
        server.timeout = 1
        logger.info(f"HTTP server successfully bound to 0.0.0.0:{port}")
        logger.info("Ready to accept connections")
        
        while not shutdown_event.is_set():
            try:
                server.handle_request()
            except Exception as req_e:
                logger.error(f"Request handling error: {req_e}")
            
    except OSError as e:
        if "Address already in use" in str(e):
            logger.critical(f"FATAL: Port {port} is already in use!")
            logger.critical("Another instance may be running. Try: pkill -f atp_emby_smart_cache.py")
        else:
            logger.critical(f"FATAL: Cannot bind to port {port}: {e}")
        sys.exit(1)
    except Exception as e:
        logger.critical(f"FATAL: {e}")
        sys.exit(1)
    
    logger.info("Shutdown complete")

if __name__ == "__main__":
    main()

]]>
</INLINE>
</FILE>

<!-- RC Service Script -->
<FILE Name="/usr/local/emhttp/plugins/&name;/rc.&name;" Mode="0755">
<INLINE>
<![CDATA[
#!/bin/bash
# rc.atp_emby_smart_cache - Service control script for ATP Emby Smart Cache
PLUGIN="atp_emby_smart_cache"
SCRIPT="/usr/local/emhttp/plugins/$PLUGIN/$PLUGIN.py"
PIDFILE="/var/run/$PLUGIN.pid"
STARTUP_LOG="/var/log/${PLUGIN}_startup.log"
DATA_DIR="/mnt/user/appdata/$PLUGIN"
CONFIG_DIR="/boot/config/plugins/$PLUGIN"

start() {
    # Check if already running
    if [ -f "$PIDFILE" ] && ps -p $(cat "$PIDFILE") > /dev/null 2>&1; then
        echo "Already running (PID $(cat $PIDFILE))"
        return 0
    fi

    # Clean stale PID file
    rm -f "$PIDFILE"

    # Ensure directories exist
    mkdir -p "$DATA_DIR/logs"
    mkdir -p "$CONFIG_DIR"

    # Start the daemon
    echo "Starting ATP Emby Smart Cache v2026.01.29..."
    nohup python3 -u "$SCRIPT" > "$STARTUP_LOG" 2>&1 &
    echo $! > "$PIDFILE"

    # Wait and verify
    sleep 2
    if ps -p $(cat "$PIDFILE") > /dev/null 2>&1; then
        echo "Started successfully (PID $(cat $PIDFILE))"
    else
        echo "Failed to start - check $STARTUP_LOG"
        rm -f "$PIDFILE"
        return 1
    fi
}

stop() {
    if [ -f "$PIDFILE" ]; then
        PID=$(cat "$PIDFILE")
        echo "Stopping (PID $PID)..."
        kill -TERM "$PID" 2>/dev/null

        # Wait for graceful shutdown
        for i in {1..10}; do
            if ! ps -p "$PID" > /dev/null 2>&1; then
                break
            fi
            sleep 1
        done

        # Force kill if still running
        if ps -p "$PID" > /dev/null 2>&1; then
            kill -9 "$PID" 2>/dev/null
        fi

        rm -f "$PIDFILE"
        echo "Stopped"
    else
        # Try to find and kill by process name
        pkill -f "$PLUGIN.py" 2>/dev/null
        echo "Stopped (no PID file)"
    fi
}

restart() {
    stop
    sleep 1
    start
}

status() {
    if [ -f "$PIDFILE" ] && ps -p $(cat "$PIDFILE") > /dev/null 2>&1; then
        echo "Running (PID $(cat $PIDFILE))"
        return 0
    else
        echo "Stopped"
        return 1
    fi
}

case "$1" in
    start)   start ;;
    stop)    stop ;;
    restart) restart ;;
    status)  status ;;
    *)       echo "Usage: $0 {start|stop|restart|status}" ;;
esac

]]>
</INLINE>
</FILE>

<!-- AJAX Handler -->
<FILE Name="/usr/local/emhttp/plugins/&name;/include/ajax.php">
<INLINE>
<![CDATA[
<?php
/**
 * ATP Emby Smart Cache - AJAX Handler v2026.01.29
 * Standalone AJAX handler - bypasses Unraid's page template system
 */
error_reporting(0);
ini_set('display_errors', 0);
header('Content-Type: application/json');

$plugin = "atp_emby_smart_cache";
$configFile = "/boot/config/plugins/{$plugin}/settings.json";

// Auto-detect server IP from HTTP_HOST (strips port if present)
$serverIp = isset($_SERVER['HTTP_HOST']) ? preg_replace('/:\d+$/', '', $_SERVER['HTTP_HOST']) : '127.0.0.1';

$defaults = [
    "ENABLED" => false,
    "EMBY_HOST" => "",
    "EMBY_API_KEY" => "",
    "DISCORD_WEBHOOK_URL" => "",
    "SERVER_PORT" => 9999,
    "UNRAID_USER_PATH" => "/mnt/user",
    "CACHE_PATH" => "/mnt/cache",
    "ARRAY_ONLY_PATH" => "/mnt/user0",
    "LOG_FILE_PATH" => "/mnt/user/appdata/atp_emby_smart_cache/logs/atp_emby_smart_cache.log",
    "RSYNC_BWLIMIT" => "0",
    "MIN_FREE_SPACE_GB" => 100,
    "MAX_FILE_SIZE_GB" => 0,
    "SKIP_HARDLINKS" => true,
    "DELETE_ON_STOP" => true,
    "CLEANUP_DELAY_HOURS" => 24,
    "MOVER_IGNORE_FILE" => "",
    "ALLOWED_EXTS" => ".mkv,.mp4,.m4v,.avi,.mov,.ts",
    "EXCLUDE_PATHS" => "",
    "DOCKER_PATH_MAP" => "",
    "COOLDOWN_MOVIE_SEC" => 60,
    "COOLDOWN_EPISODE_SEC" => 30,
    "PRECACHE_EPISODES" => 1,
    "RSYNC_RETRIES" => 3,
    "LOG_RETENTION" => 5,
    "LOG_LEVEL" => "INFO"
];

$settings = $defaults;
if (file_exists($configFile)) {
    $loaded = json_decode(file_get_contents($configFile), true);
    if ($loaded) $settings = array_merge($defaults, $loaded);
}

function apiCall($endpoint, $method = 'GET', $data = null, $timeout = 5) {
    global $settings, $serverIp;
    $port = isset($settings['SERVER_PORT']) ? intval($settings['SERVER_PORT']) : 9999;
    // Use detected server IP instead of 127.0.0.1 (PHP in Unraid can't reach localhost)
    $url = "http://{$serverIp}:{$port}{$endpoint}";

    if (function_exists('curl_init')) {
        $ch = curl_init($url);
        curl_setopt($ch, CURLOPT_RETURNTRANSFER, true);
        curl_setopt($ch, CURLOPT_TIMEOUT, $timeout);
        curl_setopt($ch, CURLOPT_CONNECTTIMEOUT, 3);
        if ($method === 'POST' && $data !== null) {
            curl_setopt($ch, CURLOPT_POST, true);
            curl_setopt($ch, CURLOPT_POSTFIELDS, json_encode($data));
            curl_setopt($ch, CURLOPT_HTTPHEADER, ['Content-Type: application/json']);
        }
        $resp = curl_exec($ch);
        $err = curl_error($ch);
        $code = curl_getinfo($ch, CURLINFO_HTTP_CODE);
        curl_close($ch);

        if (!$err && $resp !== false) {
            $decoded = json_decode($resp, true);
            if ($decoded !== null) return $decoded;
        }
        return ['success' => false, 'error' => $err ?: "HTTP {$code}"];
    }

    // Fallback to file_get_contents
    $ctx = stream_context_create(['http' => ['timeout' => $timeout]]);
    $resp = @file_get_contents($url, false, $ctx);
    if ($resp !== false) {
        $decoded = json_decode($resp, true);
        if ($decoded !== null) return $decoded;
    }
    return ['success' => false, 'error' => 'Connection failed'];
}

$action = isset($_POST['ajax']) ? $_POST['ajax'] : (isset($_GET['ajax']) ? $_GET['ajax'] : '');

if (empty($action)) {
    echo json_encode(['success' => false, 'error' => 'No action specified']);
    exit;
}

switch ($action) {
    case 'get_status':
        echo json_encode(apiCall('/api/status'));
        break;

    case 'get_managed':
        echo json_encode(apiCall('/api/managed'));
        break;

    case 'get_queue':
        echo json_encode(apiCall('/api/queue'));
        break;

    case 'get_logs':
        $lines = isset($_POST['lines']) ? intval($_POST['lines']) : 100;
        $result = apiCall("/api/logs?lines={$lines}");
        if (!$result['success']) {
            // Fallback: read log file directly
            $logPath = $settings['LOG_FILE_PATH'];
            if (file_exists($logPath)) {
                $logLines = file($logPath, FILE_IGNORE_NEW_LINES);
                $logLines = array_slice($logLines, -$lines);
                $result = ['success' => true, 'logs' => implode("\n", $logLines)];
            }
        }
        echo json_encode($result);
        break;

    case 'get_mover':
        $result = apiCall('/api/mover_ignore');
        if (!$result['success']) {
            $moverFile = $settings['MOVER_IGNORE_FILE'];
            if (!empty($moverFile) && file_exists($moverFile)) {
                $result = ['success' => true, 'content' => file_get_contents($moverFile)];
            } else {
                $result = ['success' => true, 'content' => '(not configured)'];
            }
        }
        echo json_encode($result);
        break;

    case 'get_history':
        echo json_encode(apiCall('/api/history'));
        break;

    case 'get_health':
        echo json_encode(apiCall('/api/health'));
        break;

    case 'get_stats':
        echo json_encode(apiCall('/api/stats'));
        break;

    case 'force_cleanup':
        $path = isset($_POST['path']) ? $_POST['path'] : '';
        // Use 120 second timeout for large file operations
        echo json_encode(apiCall('/api/cleanup', 'POST', ['path' => $path], 120));
        break;

    case 'rebuild_state':
        // Use 60 second timeout for state rebuild
        echo json_encode(apiCall('/api/rebuild', 'POST', [], 60));
        break;

    case 'reset_stats':
        // Reset statistics
        echo json_encode(apiCall('/api/reset_stats', 'POST', [], 30));
        break;

    case 'clear_log':
        $logPath = $settings['LOG_FILE_PATH'];
        if (file_exists($logPath)) {
            file_put_contents($logPath, "");
            echo json_encode(['success' => true, 'message' => 'Log cleared']);
        } else {
            echo json_encode(['success' => false, 'error' => 'Log file not found']);
        }
        break;

    case 'save_settings':
        $new = $defaults;
        foreach ($defaults as $k => $v) {
            if (isset($_POST[$k])) {
                if (is_bool($v) || in_array($k, ['ENABLED','SKIP_HARDLINKS','DELETE_ON_STOP'])) {
                    $new[$k] = ($_POST[$k] === 'true' || $_POST[$k] === '1');
                } else {
                    $new[$k] = trim($_POST[$k]);
                }
            }
        }
        $saved = file_put_contents($configFile, json_encode($new, JSON_PRETTY_PRINT));
        exec("/usr/local/emhttp/plugins/{$plugin}/rc.atp_emby_smart_cache restart 2>&1", $out);
        echo json_encode(['success' => $saved !== false, 'message' => 'Settings saved, service restarted']);
        break;

    case 'debug':
        $port = $settings['SERVER_PORT'];
        $apiUrl = "http://{$serverIp}:{$port}/api/status";
        $debug = [
            'php_version' => PHP_VERSION,
            'curl_available' => function_exists('curl_init'),
            'server_ip' => $serverIp,
            'port' => $port,
            'api_url' => $apiUrl,
            'config_exists' => file_exists($configFile)
        ];

        // Test curl with server IP
        if (function_exists('curl_init')) {
            $ch = curl_init($apiUrl);
            curl_setopt($ch, CURLOPT_RETURNTRANSFER, true);
            curl_setopt($ch, CURLOPT_TIMEOUT, 3);
            $resp = curl_exec($ch);
            $debug['curl_response'] = substr($resp ?: '', 0, 200);
            $debug['curl_error'] = curl_error($ch);
            $debug['curl_http_code'] = curl_getinfo($ch, CURLINFO_HTTP_CODE);
            curl_close($ch);
        }

        echo json_encode(['success' => true, 'debug' => $debug]);
        break;

    default:
        echo json_encode(['success' => false, 'error' => 'Unknown action: ' . $action]);
}

]]>
</INLINE>
</FILE>

<!-- Post-install: Set up directories and auto-start -->
<FILE Run="/bin/bash">
<INLINE>
<![CDATA[
#!/bin/bash
PLUGIN_NAME="atp_emby_smart_cache"
DATA_DIR="/mnt/user/appdata/${PLUGIN_NAME}"
CONFIG_DIR="/boot/config/plugins/${PLUGIN_NAME}"
RC_SCRIPT="/usr/local/emhttp/plugins/${PLUGIN_NAME}/rc.${PLUGIN_NAME}"
GO_FILE="/boot/config/go"
LOG="/var/log/${PLUGIN_NAME}_install.log"

echo "$(date): Post-install starting" >> "$LOG"

# Create directories
mkdir -p "$DATA_DIR/logs"
mkdir -p "$CONFIG_DIR"

# Make scripts executable
chmod +x "/usr/local/emhttp/plugins/${PLUGIN_NAME}/${PLUGIN_NAME}.py"
chmod +x "$RC_SCRIPT"

# Add to startup if not already there
if ! grep -q "rc.${PLUGIN_NAME}" "$GO_FILE" 2>/dev/null; then
    echo "" >> "$GO_FILE"
    echo "# Start ATP Emby Smart Cache" >> "$GO_FILE"
    echo "$RC_SCRIPT start &" >> "$GO_FILE"
    echo "$(date): Added to $GO_FILE" >> "$LOG"
fi

# Start the service in background with delay
(
    sleep 5
    "$RC_SCRIPT" start >> "$LOG" 2>&1
) &

echo "$(date): Post-install complete" >> "$LOG"
echo ""
echo "ATP Emby Smart Cache v2026.01.29b installed!"
echo "Service will start in 5 seconds..."
echo ""
echo "IMPORTANT: Configure settings before enabling:"
echo "  - Emby Host URL"
echo "  - Emby API Key"
echo "  - Cache Path"
]]>
</INLINE>
</FILE>

<!-- Uninstall script -->
<FILE Run="/bin/bash" Method="remove">
<INLINE>
<![CDATA[
#!/bin/bash
PLUGIN_NAME="atp_emby_smart_cache"
RC_SCRIPT="/usr/local/emhttp/plugins/${PLUGIN_NAME}/rc.${PLUGIN_NAME}"
GO_FILE="/boot/config/go"

echo "Removing ATP Emby Smart Cache..."

# Stop service
if [ -f "$RC_SCRIPT" ]; then
    "$RC_SCRIPT" stop 2>/dev/null
fi
pkill -f "${PLUGIN_NAME}.py" 2>/dev/null || true
rm -f "/var/run/${PLUGIN_NAME}.pid"

# Remove from startup
if [ -f "$GO_FILE" ]; then
    sed -i "/# Start ATP Emby Smart Cache/d" "$GO_FILE"
    sed -i "/rc.${PLUGIN_NAME}/d" "$GO_FILE"
fi

# Remove plugin files (keep config and data)
rm -rf "/usr/local/emhttp/plugins/${PLUGIN_NAME}"
rm -f "/var/log/${PLUGIN_NAME}_install.log"
rm -f "/var/log/${PLUGIN_NAME}_startup.log"

echo "ATP Emby Smart Cache removed."
echo "Config preserved at: /boot/config/plugins/${PLUGIN_NAME}"
echo "Data preserved at: /mnt/user/appdata/${PLUGIN_NAME}"
]]>
</INLINE>
</FILE>

</PLUGIN>
